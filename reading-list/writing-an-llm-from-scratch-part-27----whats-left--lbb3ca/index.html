<!DOCTYPE html><html lang="zh-CN" data-astro-cid-sckkx6r4> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.17.1"><meta name="description" content="2024 年 12 月 22 日，我写道：
在圣诞假期（可能还会持续更久），我计划研读
Sebastian Raschka 的著作《从零开始构建大型语言模型》。
我期望"><meta http-equiv="Content-Security-Policy" content="default-src 'self'; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'; img-src 'self' data: https:; connect-src 'self'; font-src 'self' data:;"><link rel="canonical" href="https://blog.yuyins.com/reading-list/writing-an-llm-from-scratch-part-27----whats-left--lbb3ca/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://blog.yuyins.com/reading-list/writing-an-llm-from-scratch-part-27----whats-left--lbb3ca/"><meta property="og:title" content="从零开始编写 LLM，第 27 部分——还剩下什么，接下来又会怎样？"><meta property="og:description" content="2024 年 12 月 22 日，我写道：
在圣诞假期（可能还会持续更久），我计划研读
Sebastian Raschka 的著作《从零开始构建大型语言模型》。
我期望"><meta property="og:image" content="https://blog.yuyins.com/favicon.svg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://blog.yuyins.com/reading-list/writing-an-llm-from-scratch-part-27----whats-left--lbb3ca/"><meta property="twitter:title" content="从零开始编写 LLM，第 27 部分——还剩下什么，接下来又会怎样？"><meta property="twitter:description" content="2024 年 12 月 22 日，我写道：
在圣诞假期（可能还会持续更久），我计划研读
Sebastian Raschka 的著作《从零开始构建大型语言模型》。
我期望"><meta property="twitter:image" content="https://blog.yuyins.com/favicon.svg"><title>从零开始编写 LLM，第 27 部分——还剩下什么，接下来又会怎样？</title><!-- Theme and color scheme script (runs before page loads to prevent flash) --><script>
			// 初始化配色方案 - 默认使用 stone-amber
			const colorScheme = localStorage.getItem('colorScheme') || 'stone-amber';
			document.documentElement.setAttribute('data-color', colorScheme);

			// 强制使用浅色主题
			document.documentElement.setAttribute('data-theme', 'light');
		</script><link rel="stylesheet" href="/_astro/_slug_.ChsEGtcr.css">
<style>.blog-post-container[data-astro-cid-wrgicudb]{width:100%;margin:0 auto;padding:2rem 0}.blog-post[data-astro-cid-wrgicudb]{width:100%;min-width:0;max-width:42rem;margin:0 auto}.article-header[data-astro-cid-wrgicudb]{margin-bottom:2rem;padding-bottom:1rem;border-bottom:1px solid var(--border)}.article-header[data-astro-cid-wrgicudb] h1[data-astro-cid-wrgicudb]{font-size:2rem;line-height:1.3;margin-bottom:1rem;font-weight:700;color:var(--foreground);word-break:break-word}.article-meta[data-astro-cid-wrgicudb]{display:flex;align-items:center;gap:.5rem;font-size:.875rem;color:var(--muted-foreground)}.source-tag[data-astro-cid-wrgicudb]{background-color:var(--muted);color:var(--foreground);padding:.125rem .5rem;border-radius:9999px;font-weight:500;font-size:.75rem;text-decoration:none;transition:opacity .2s}.source-tag[data-astro-cid-wrgicudb]:hover{opacity:.8}.separator[data-astro-cid-wrgicudb]{color:var(--border)}.article-content[data-astro-cid-wrgicudb]{line-height:1.8;margin-bottom:3rem;font-size:1.0625rem;color:var(--foreground)}.article-content[data-astro-cid-wrgicudb] h2{margin-top:2rem;margin-bottom:1rem;font-size:1.5rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] h3{margin-top:1.5rem;margin-bottom:.75rem;font-size:1.25rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] p{margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] a{color:var(--accent);text-decoration:underline;text-underline-offset:2px}.article-content[data-astro-cid-wrgicudb] img{max-width:100%;height:auto;border-radius:.5rem;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] blockquote{border-left:4px solid var(--border);padding-left:1rem;margin:1.5rem 0;color:var(--muted-foreground);font-style:italic}.article-content[data-astro-cid-wrgicudb] pre{background:var(--muted);padding:1rem;border-radius:.5rem;overflow-x:auto;font-family:monospace;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] ul,.article-content[data-astro-cid-wrgicudb] ol{padding-left:1.5rem;margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] li{margin-bottom:.5rem}.article-footer[data-astro-cid-wrgicudb]{padding-top:2rem;border-top:1px solid var(--border);display:flex;flex-direction:column;gap:1.5rem;align-items:center}.action-row[data-astro-cid-wrgicudb]{display:flex;justify-content:center}.read-original-btn[data-astro-cid-wrgicudb]{display:inline-flex;align-items:center;gap:.5rem;padding:.75rem 1.5rem;background-color:var(--foreground);color:var(--background);border-radius:.5rem;font-weight:500;text-decoration:none;transition:opacity .2s}.read-original-btn[data-astro-cid-wrgicudb]:hover{opacity:.9}.back-to-list[data-astro-cid-wrgicudb]{text-align:center}.back-link[data-astro-cid-wrgicudb]{color:var(--muted-foreground);text-decoration:none;font-size:.875rem;transition:color .2s}.back-link[data-astro-cid-wrgicudb]:hover{color:var(--foreground)}
</style></head> <body data-astro-cid-sckkx6r4> <a id="skip-to-content" href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:top-4 focus:left-4 focus:z-50 focus:px-4 focus:py-2 focus:bg-accent focus:text-background" data-astro-cid-sckkx6r4>Skip to content</a> <header class="header" data-astro-cid-3ef6ksr2> <nav class="header-nav" aria-label="Main navigation" data-astro-cid-3ef6ksr2> <a href="/" class="header-logo" data-astro-cid-3ef6ksr2>
AstroBlog
</a> <div class="header-links" data-astro-cid-3ef6ksr2> <ul class="nav-list" data-astro-cid-3ef6ksr2> <li data-astro-cid-3ef6ksr2> <a href="/" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 文章 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/category" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 分类 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/reading-list" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 订阅 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/about" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 关于 </a> </li> </ul> <div class="header-actions" data-astro-cid-3ef6ksr2> <div id="search" data-astro-cid-otpdt6jm> <button id="search-button" class="search-toggle" aria-label="打开搜索" title="搜索 (⌘K)" data-astro-cid-otpdt6jm> <svg class="search-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <circle cx="11" cy="11" r="7" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></circle> <path d="M20 20L16.5 16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></path> </svg> </button> <dialog id="search-dialog" class="search-modal" data-astro-cid-otpdt6jm> <div class="modal-content" data-astro-cid-otpdt6jm> <div class="modal-header" data-astro-cid-otpdt6jm> <h2 class="modal-title" data-astro-cid-otpdt6jm>搜索文章</h2> <button id="close-search" class="close-button" aria-label="关闭搜索" data-astro-cid-otpdt6jm> <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <path d="M18 6L6 18M6 6l12 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-otpdt6jm></path> </svg> </button> </div> <div id="pagefind-ui" data-astro-cid-otpdt6jm></div> </div> </dialog> </div> <script type="module">let d=!1;const c="pagefind-loaded";async function l(t=0){if(sessionStorage.getItem(c)==="true")return g(),!0;const r=document.getElementById("pagefind-ui");if(!r)return!1;r.innerHTML='<div style="padding: 2rem; text-align: center; color: var(--muted-foreground);">加载中...</div>';try{return await new Promise((o,s)=>{const a=document.createElement("script");a.src="/pagefind/pagefind-ui.js",a.onload=o,a.onerror=s,document.head.appendChild(a)}),g(),sessionStorage.setItem(c,"true"),!0}catch(i){return console.error("Failed to load search:",i),t<2?(console.log(`Retrying search load... (${t+1}/2)`),await new Promise(o=>setTimeout(o,1e3)),l(t+1)):(r&&(r.innerHTML=`
          <div style="padding: 2rem; text-align: center;">
            <p style="color: var(--muted-foreground); margin-bottom: 1rem;">搜索功能加载失败</p>
            <button id="retry-search" style="padding: 0.5rem 1rem; background: var(--accent); color: var(--accent-foreground); border: none; border-radius: 0.375rem; cursor: pointer;">
              重试
            </button>
          </div>
        `,document.getElementById("retry-search")?.addEventListener("click",()=>{sessionStorage.removeItem(c),l(0)})),!1)}}function g(){typeof PagefindUI<"u"&&(new PagefindUI({element:"#pagefind-ui",showSubResults:!0,showImages:!1,excerptLength:15,translations:{placeholder:"搜索文章...",clear_search:"清除",load_more:"加载更多",search_label:"搜索此站点",filters_label:"筛选",zero_results:"未找到结果 [SEARCH_TERM]",many_results:"找到 [COUNT] 个结果 [SEARCH_TERM]",one_result:"找到 [COUNT] 个结果 [SEARCH_TERM]",alt_search:"未找到 [SEARCH_TERM] 的结果。显示 [DIFFERENT_TERM] 的结果",search_suggestion:"未找到 [SEARCH_TERM] 的结果。尝试以下搜索：",searching:"搜索中 [SEARCH_TERM]..."}}),setTimeout(()=>{const t=document.querySelector(".pagefind-ui__search-input");t instanceof HTMLElement&&t.focus()},100))}function u(){if(d)return;d=!0;const t=document.getElementById("search-button"),n=document.getElementById("search-dialog"),r=document.getElementById("close-search");if(!t||!n||!r)return;let i=sessionStorage.getItem(c)==="true";const o=async()=>{n.showModal(),document.body.style.overflow="hidden",i?setTimeout(()=>{const e=document.querySelector(".pagefind-ui__search-input");e instanceof HTMLElement&&e.focus()},100):await l()&&(i=!0)},s=()=>{n.close(),document.body.style.overflow=""},a=e=>{e.target===n&&s()},m=e=>{e.key==="Escape"&&n.open&&s()},f=e=>{(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),n.open?s():o())};t.addEventListener("click",o),r.addEventListener("click",s),n.addEventListener("click",a),document.addEventListener("keydown",m),document.addEventListener("keydown",f),document.addEventListener("astro:before-swap",()=>{t.removeEventListener("click",o),r.removeEventListener("click",s),n.removeEventListener("click",a),document.removeEventListener("keydown",m),document.removeEventListener("keydown",f),d=!1},{once:!0})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",u):u();document.addEventListener("astro:page-load",u);</script> <link href="/pagefind/pagefind-ui.css" rel="stylesheet">  </div> </div> </nav> </header>  <main id="main-content" data-pagefind-body class="main-content main-content--wide" data-astro-cid-sckkx6r4>  <div class="blog-post-container" data-astro-cid-wrgicudb> <article class="blog-post" data-astro-cid-wrgicudb> <header class="article-header" data-astro-cid-wrgicudb> <h1 data-astro-cid-wrgicudb>从零开始编写 LLM，第 27 部分——还剩下什么，接下来又会怎样？</h1> <div class="article-meta" data-astro-cid-wrgicudb> <a href="https://gilesthomas.com" target="_blank" rel="noopener noreferrer" class="source-tag" data-astro-cid-wrgicudb>gilesthomas.com</a> <span class="separator" data-astro-cid-wrgicudb>·</span> <time data-astro-cid-wrgicudb>2025年11月4日</time> </div> </header> <!-- 使用清洗后的安全 HTML 内容 --> <div class="article-content app-prose" data-astro-cid-wrgicudb><p>On 22 December 2024, <a href="/2024/12/llm-from-scratch-1" target="_blank" rel="noopener noreferrer">I wrote</a>:</p>

<blockquote>
  <p>Over the Christmas break (and probably beyond) I'm planning to work through
  <a href="https://sebastianraschka.com/" target="_blank" rel="noopener noreferrer">Sebastian Raschka</a>'s book
  "<a href="https://www.manning.com/books/build-a-large-language-model-from-scratch" target="_blank" rel="noopener noreferrer">Build a Large Language Model (from Scratch)</a>".
  I'm expecting to get through a chapter or less a day, in order to give things
  time to percolate properly.  Each day, or perhaps each chapter, I'll post here
  about anything I find particularly interesting.</p>
</blockquote>

<p>More than ten months and 26 blog posts later, I've reached the end of the main
body of the book -- there's just the appendices to go.
Even allowing for the hedging, my optimism was adorable.</p>

<p>I don't want to put anyone else off the book by saying that, though!  I expect most people
will get through it much faster.  I made a deliberate decision at the start to write up
everything I learned as I worked through it, and that, I think, has helped me solidify
things in my mind much better than I would have done if I'd only been reading it and doing
the exercises.  But on the other hand, writing things up does take a <em>lot</em> of time,
much more than the actual learning does.  It's worth it for me, but probably isn't
for everyone.</p>

<p>So, what next?  I've finished the main body of the book, and built up a decent backlog
as I did so.  What do I need to do before I can treat my "LLM from scratch" journey as done?
And what other ideas have come up while I worked through it that might be good bases for
future, similar series?</p>
<p>There are a few sources of ideas for this -- from the book itself and its supplementary
material, from notes I've made as I went along, and from other things that I've kept on
a mental checklist.</p>

<h3>The appendices and supplementary material</h3>

<p>There are five appendices:</p>

<ul>
<li>A: An introduction to PyTorch</li>
<li>B: References and further reading</li>
<li>C: Exercise solutions</li>
<li>D: Adding bells and whistles to the training loop</li>
<li>E: Parameter-efficient fine-tuning with LoRA</li>
</ul>

<p>Raschka also gives a link at the end of chapter 7 to a notebook showing how to do
further fine tuning using <a href="https://github.com/rasbt/LLMs-from-scratch/tree/main/ch07/04_preference-tuning-with-dpo" target="_blank" rel="noopener noreferrer">Direct Preference Optimization</a>,
which also looks fascinating, and he's working on a new project,
"<a href="https://github.com/rasbt/reasoning-from-scratch" target="_blank" rel="noopener noreferrer">Build a reasoning model (from scratch)</a>".</p>

<h3>Things I've deferred myself</h3>

<p>While working through the book, I've deliberately deferred various
things.  I'd kind of lost track of all of them, so I gave ChatGPT the source
markdown for all of the posts in this series, and asked it to find where I'd done that.
It did an amazing job!  There were three categories: long context and attention efficiency,
maths, and optimisers.</p>

<h4>Long context and attention efficiency.</h4>

<p>The model we've built in the book has
a context length of 1,024 tokens, and is O(n2) in both space and time
with respect to the number of tokens you feed it.  There are lots of things that
people do to work around that.  Things I need to learn:</p>

<ul>
<li><strong>The KV cache</strong>.  This is basic stuff and I feel I sorta-kinda understand it, but
I haven't written about it so I can't be sure.  It's a pretty obvious enhancement
to avoid repeating work when generating autoregressively -- that is, the normal
setup where in order to generate n tokens, we give the model its input,
sample our first token from its predictions, then feed the whole thing -- the input
and that first token -- back in for the second token, and so on.  Obviously,
because attention is causal, we're doing exactly the same work every time for
all of the tokens in each round apart from the last one, so it makes sense
to cache things.  The result is that generating the first token is still O(n2), but
subsequent ones will be something more like O(n) each.  That's why real-world modern models tend to take
a while pondering before they generate the first token but then speed up -- they
need to fill their cache.</li>
<li><strong>FlashAttention</strong> and related things: there are lots of ways people have found to reduce the cost of
attention generally, but this seems to be the most popular one, or at least the best
to get started with.</li>
<li><strong>Better positional embeddings</strong>: the context length of our GPT-2-style LLM is fixed
in part because you need position embeddings for every possible input position.
That means that we can never extend it.  More modern LLMs use better ways to
represent positions -- Rotary Position Embeddings (RoPE) look like they're
very popular.</li>
</ul>

<h4>Maths</h4>

<p>I really want to understand softmax at a better level than "it's a magic thing
that turns logits into probabilities".  I'd also like to learn more about higher-order
tensor operations -- the ones that we use in the book are essentially treating
the extra dimensions as the batch, but I believe that there's more to it than that.</p>

<h4>Optimisers</h4>

<p>I really want to understand in reasonable depth what optimisers do.  I know that
they make gradient updates work better than they do with simple gradient descent.
But how?</p>

<hr />

<p>That was the set of things I noted at the time I wrote the posts so far, but there are a few more that
come to mind as I write this.</p>

<h3>Automatic differentiation and the backward pass</h3>

<p>In some comments that he made on posts in this series, <code>Simon</code> said that it seems like this book
isn't really "from scratch", given that we rely on PyTorch's magic to handle the
backward pass.</p>

<p>He's 100% right!  I think I understand why it is that way, though.
There would be two different ways that I can see for the book to do it:</p>

<ul>
<li>Manually code a backward pass to go with the forward pass on each of our modules.
Simon did this, and was kind enough to share his code with me -- it looks like one of those
things (like attention) that is pretty hard to get your head around initially, but
once it clicks it's super-clear.  Definitely kudos to him for getting it all to work!
The problem with this is that I don't think any
ML practitioners do this nowadays, because automatic differentiation
is there in every popular framework.  So it might be a good learning experience,
but also might nudge people into an unprofitable direction.</li>
<li>Create our own automatic differentiation system.  Andrej Karpathy pops up again
when looking into this; he created <a href="https://github.com/karpathy/micrograd" target="_blank" rel="noopener noreferrer">micrograd</a>,
which handles back-propagation for scalar functions.  That's really clever -- but
it would be hard, and a bit of a side quest from the point of the book.  Also,
the most interesting stuff (at least from what little I know) for automatic
differentiation is how you do it with non-scalars -- the matrices and higher-order
tensors that our LLM uses.  From what Simon says, this is where you need to use
the mysterious Jacobian matrices I've heard about in the context of back-propagation.</li>
</ul>

<p>I think I'd definitely like to revisit that at some point.</p>

<h3>Tokenisers</h3>

<p>Another one from Simon; while the book does explain how tokenisers work, even down
to a high-level overview of byte-pair encoding, we don't write our own.  Again, I can
see why this is -- we load in the GPT-2 weights, so we need to use that model's tokeniser.
And there's no point in writing our own if we're just going to throw it away.</p>

<p>But perhaps a bit of time playing with one would be useful?</p>

<h4>Trying to train the LLM as a base model</h4>

<p>The book, quite reasonably, shows you how to train your LLM, does a basic train
on a small dataset, and then we switch to downloading the "pre-cooked" weights
from OpenAI.  That makes sense given that not every reader will have access to enough
hardware to really train from scratch.</p>

<p>But given that I was getting a pretty good training speed on my own hardware, perhaps
I could train a model really from scratch, perhaps using one of the smaller
<a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb" target="_blank" rel="noopener noreferrer">FineWeb</a> datasets?  Even if
I can't do it locally, perhaps it might be doable on a rented cloud machine, like
the Lambda Labs ones I used when <a href="/fine-tuning" target="_blank" rel="noopener noreferrer">fine-tuning Llama 3</a>?</p>

<p>After all, Andrej Karpathy is training <a href="https://github.com/karpathy/nanochat/discussions/1" target="_blank" rel="noopener noreferrer">a full model that you can chat with for
$100</a>.</p>

<h3>Building an LLM from scratch on my own.</h3>

<p>I don't think I ever mentioned this on the blog, but one important plan for me is to
try to build an LLM from scratch, only using my own blog posts and what I remember --
no looking at the book.  If I can do that, then I can be reasonably sure that I really
have learned it all.</p>

<p>I'm also thinking that I'll do that using a different library -- that is, not PyTorch.
That would stop me from regurgitating code that I've learned.  If you're reading this
within a day or so of the post's publication, I'm
<a href="https://x.com/gpjt/status/1985434030880293004" target="_blank" rel="noopener noreferrer">running a poll on X/Twitter about which framework to use</a>.
If you have an opinion, please do stop by and vote :-)</p>

<h3>Mixture-of-experts</h3>

<p>It feels like almost every new model these days is an MoE.  I have read a lot around the
subject and would love to build on it.  Essentially, instead of having just one feed-forward network
after your attention heads, you have several.  In front of them you have a router -- a trainable
network of some kind -- that tells you which of these "expert" FFNs the token should be
forwarded to.  You then send it to the top (or top k) experts, while leaving the others
inactive.  The result is that you have more space (in terms of parameters) for the LLM
to know about things, but not all of those parameters are active during inference -- so
your model is smarter but still fast.</p>

<p>There's a bunch of interesting stuff there, from how you build it in the first place,
to how you handle the fact that you're processing lots of tokens at once -- multiple
tokens in each sequence and multiple sequences in a batch.</p>

<p>It would be a pretty cool follow-on to the "my own LLM" series, thinking about it.</p>

<h3>So, what next?</h3>

<p>I definitely don't think I need to do all of those things in order to wrap up
this series.  Here's the subset I'm planning on doing:</p>

<ul>
<li>Training the full GPT-2 base model myself.  I'm 100% going to try this.</li>
<li>From the appendices -- anything that surprises me from the one on PyTorch, and
perhaps from the "bells and whistles" in the training loop.  The others I either
won't do, or will pick up later.</li>
<li>Building my own LLM from scratch in a different framework, without using the book.
That is, I think, essential, and perhaps would be the crowning post of this series.
It would be a nice way to end it, wouldn't it?</li>
</ul>

<p>For the other things, I think there are some potential future series to write.</p>

<ul>
<li>Improving context length -- RoPE and other tricks --
sounds like an excellent series to start on when I'm done with this.  AIs tell
me that other interesting things to look into would be ALiBi, NTK/YaRN scaling, and positional interpolation.</li>
<li>Improving performance: the KV cache, FlashAttention, and other performance enhancements
likewise feel like they could make a good series.</li>
<li>I also want to do a separate series on LoRA.  In that, I'll draw on appendix E from
this book, but also on other tutorials.</li>
<li>Likewise DPO, along with other post-training that can be done to make models more
useful as chatbots, like Reinforcement Learning.   I'd really like to spend some
time understanding that area.  (And Raschka's upcoming reasoning model book might
fit into that category too.)</li>
<li>Optimisers: Adam, AdamW, maybe Muon (though the latter scares me a bit).</li>
<li>The maths -- softmax and higher-order tensor calculations -- also seems to belong
in another series, perhaps an extension of the various "maths for AI" posts I've
done in the past.</li>
<li>Automatic differentiation and the backward pass; that would make a great series.</li>
<li>A mixture-of-experts model would be excellent fun, I think.</li>
<li>Tokenisers would be a great stand-alone post, at least at the level that I can
see myself covering it.  Perhaps that would develop into a series if I found
myself getting sucked in.</li>
</ul>

<p>I'm certainly not promising that I'll write up all (or even any) of that second list, but they
all seem really tempting to me right now.  If you're particularly interested in seeing
my take on any of them, please do leave a comment below.</p>

<h3>Coming up...</h3>

<p>I think the next post in this series -- maybe the next several posts -- will be on
trying to train the model code provided in the book from scratch to produce my own
base model.  Stay tuned!</p>

<p><a href="/2025/12/llm-from-scratch-28-training-a-base-model-from-scratch" target="_blank" rel="noopener noreferrer">Here's a link to the next post in this series</a>.</p>
</div> <footer class="article-footer" data-astro-cid-wrgicudb> <div class="action-row" data-astro-cid-wrgicudb> <a href="https://www.gilesthomas.com/2025/11/llm-from-scratch-27-whats-left-and-whats-next" target="_blank" rel="noopener noreferrer" class="read-original-btn" data-astro-cid-wrgicudb>
阅读原文 ↗
</a> </div> <div class="back-to-list" data-astro-cid-wrgicudb> <a href="/reading-list" class="back-link" data-astro-cid-wrgicudb>← 返回订阅列表</a> </div> </footer> </article> </div>  </main> <footer class="site-footer" aria-label="Site footer" data-astro-cid-sz7xmlte> <div class="footer-content" data-astro-cid-sz7xmlte> <p class="footer-text" data-astro-cid-sz7xmlte>
&copy; 2026 AstroBlog
</p> <p class="footer-text" data-astro-cid-sz7xmlte>
Built with  <a href="https://astro.build/" target="_blank" rel="noopener noreferrer" class="footer-link" data-astro-cid-sz7xmlte>
Astro
</a> </p> </div> </footer>  </body></html> 