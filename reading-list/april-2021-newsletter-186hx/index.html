<!DOCTYPE html><html lang="zh-CN" data-astro-cid-sckkx6r4> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.16.1"><meta name="description" content="with links on AI scaling, particular new East Asian record-breaking work &#38; deep reinforcement learning."><link rel="canonical" href="https://blog.yuyins.com/reading-list/april-2021-newsletter-186hx/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://blog.yuyins.com/reading-list/april-2021-newsletter-186hx/"><meta property="og:title" content="April 2021 newsletter"><meta property="og:description" content="with links on AI scaling, particular new East Asian record-breaking work &#38; deep reinforcement learning."><meta property="og:image" content="https://blog.yuyins.com/favicon.svg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://blog.yuyins.com/reading-list/april-2021-newsletter-186hx/"><meta property="twitter:title" content="April 2021 newsletter"><meta property="twitter:description" content="with links on AI scaling, particular new East Asian record-breaking work &#38; deep reinforcement learning."><meta property="twitter:image" content="https://blog.yuyins.com/favicon.svg"><title>April 2021 newsletter</title><!-- Theme and color scheme script (runs before page loads to prevent flash) --><script>
			// åˆå§‹åŒ–é…è‰²æ–¹æ¡ˆ - é»˜è®¤ä½¿ç”¨ stone-amber
			const colorScheme = localStorage.getItem('colorScheme') || 'stone-amber';
			document.documentElement.setAttribute('data-color', colorScheme);

			// å¼ºåˆ¶ä½¿ç”¨æµ…è‰²ä¸»é¢˜
			document.documentElement.setAttribute('data-theme', 'light');
		</script><link rel="stylesheet" href="/_astro/_slug_.C-G01a-E.css">
<style>.blog-post-container[data-astro-cid-wrgicudb]{width:100%;margin:0 auto;padding:2rem 0}.blog-post[data-astro-cid-wrgicudb]{width:100%;min-width:0;max-width:42rem;margin:0 auto}.article-header[data-astro-cid-wrgicudb]{margin-bottom:2rem;padding-bottom:1rem;border-bottom:1px solid var(--border)}.article-header[data-astro-cid-wrgicudb] h1[data-astro-cid-wrgicudb]{font-size:2rem;line-height:1.3;margin-bottom:1rem;font-weight:700;color:var(--foreground);word-break:break-word}.article-meta[data-astro-cid-wrgicudb]{display:flex;align-items:center;gap:.5rem;font-size:.875rem;color:var(--muted-foreground)}.source-tag[data-astro-cid-wrgicudb]{background-color:var(--muted);color:var(--foreground);padding:.125rem .5rem;border-radius:9999px;font-weight:500;font-size:.75rem;text-decoration:none;transition:opacity .2s}.source-tag[data-astro-cid-wrgicudb]:hover{opacity:.8}.separator[data-astro-cid-wrgicudb]{color:var(--border)}.article-content[data-astro-cid-wrgicudb]{line-height:1.8;margin-bottom:3rem;font-size:1.0625rem;color:var(--foreground)}.article-content[data-astro-cid-wrgicudb] h2{margin-top:2rem;margin-bottom:1rem;font-size:1.5rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] h3{margin-top:1.5rem;margin-bottom:.75rem;font-size:1.25rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] p{margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] a{color:var(--accent);text-decoration:underline;text-underline-offset:2px}.article-content[data-astro-cid-wrgicudb] img{max-width:100%;height:auto;border-radius:.5rem;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] blockquote{border-left:4px solid var(--border);padding-left:1rem;margin:1.5rem 0;color:var(--muted-foreground);font-style:italic}.article-content[data-astro-cid-wrgicudb] pre{background:var(--muted);padding:1rem;border-radius:.5rem;overflow-x:auto;font-family:monospace;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] ul,.article-content[data-astro-cid-wrgicudb] ol{padding-left:1.5rem;margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] li{margin-bottom:.5rem}.article-footer[data-astro-cid-wrgicudb]{padding-top:2rem;border-top:1px solid var(--border);display:flex;flex-direction:column;gap:1.5rem;align-items:center}.action-row[data-astro-cid-wrgicudb]{display:flex;justify-content:center}.read-original-btn[data-astro-cid-wrgicudb]{display:inline-flex;align-items:center;gap:.5rem;padding:.75rem 1.5rem;background-color:var(--foreground);color:var(--background);border-radius:.5rem;font-weight:500;text-decoration:none;transition:opacity .2s}.read-original-btn[data-astro-cid-wrgicudb]:hover{opacity:.9}.back-to-list[data-astro-cid-wrgicudb]{text-align:center}.back-link[data-astro-cid-wrgicudb]{color:var(--muted-foreground);text-decoration:none;font-size:.875rem;transition:color .2s}.back-link[data-astro-cid-wrgicudb]:hover{color:var(--foreground)}
</style></head> <body data-astro-cid-sckkx6r4> <a id="skip-to-content" href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:top-4 focus:left-4 focus:z-50 focus:px-4 focus:py-2 focus:bg-accent focus:text-background" data-astro-cid-sckkx6r4>Skip to content</a> <header class="header" data-astro-cid-3ef6ksr2> <nav class="header-nav" aria-label="Main navigation" data-astro-cid-3ef6ksr2> <a href="/" class="header-logo" data-astro-cid-3ef6ksr2>
AstroBlog
</a> <div class="header-links" data-astro-cid-3ef6ksr2> <ul class="nav-list" data-astro-cid-3ef6ksr2> <li data-astro-cid-3ef6ksr2> <a href="/" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> æ–‡ç«  </a> </li><li data-astro-cid-3ef6ksr2> <a href="/category" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> åˆ†ç±» </a> </li><li data-astro-cid-3ef6ksr2> <a href="/reading-list" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> è®¢é˜… </a> </li><li data-astro-cid-3ef6ksr2> <a href="/about" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> å…³äº </a> </li> </ul> <div class="header-actions" data-astro-cid-3ef6ksr2> <div id="search" data-astro-cid-otpdt6jm> <button id="search-button" class="search-toggle" aria-label="æ‰“å¼€æœç´¢" title="æœç´¢ (âŒ˜K)" data-astro-cid-otpdt6jm> <svg class="search-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <circle cx="11" cy="11" r="7" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></circle> <path d="M20 20L16.5 16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></path> </svg> </button> <dialog id="search-dialog" class="search-modal" data-astro-cid-otpdt6jm> <div class="modal-content" data-astro-cid-otpdt6jm> <div class="modal-header" data-astro-cid-otpdt6jm> <h2 class="modal-title" data-astro-cid-otpdt6jm>æœç´¢æ–‡ç« </h2> <button id="close-search" class="close-button" aria-label="å…³é—­æœç´¢" data-astro-cid-otpdt6jm> <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <path d="M18 6L6 18M6 6l12 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-otpdt6jm></path> </svg> </button> </div> <div id="pagefind-ui" data-astro-cid-otpdt6jm></div> </div> </dialog> </div> <script type="module">let d=!1;const c="pagefind-loaded";async function l(t=0){if(sessionStorage.getItem(c)==="true")return g(),!0;const r=document.getElementById("pagefind-ui");if(!r)return!1;r.innerHTML='<div style="padding: 2rem; text-align: center; color: var(--muted-foreground);">åŠ è½½ä¸­...</div>';try{return await new Promise((o,s)=>{const a=document.createElement("script");a.src="/pagefind/pagefind-ui.js",a.onload=o,a.onerror=s,document.head.appendChild(a)}),g(),sessionStorage.setItem(c,"true"),!0}catch(i){return console.error("Failed to load search:",i),t<2?(console.log(`Retrying search load... (${t+1}/2)`),await new Promise(o=>setTimeout(o,1e3)),l(t+1)):(r&&(r.innerHTML=`
          <div style="padding: 2rem; text-align: center;">
            <p style="color: var(--muted-foreground); margin-bottom: 1rem;">æœç´¢åŠŸèƒ½åŠ è½½å¤±è´¥</p>
            <button id="retry-search" style="padding: 0.5rem 1rem; background: var(--accent); color: var(--accent-foreground); border: none; border-radius: 0.375rem; cursor: pointer;">
              é‡è¯•
            </button>
          </div>
        `,document.getElementById("retry-search")?.addEventListener("click",()=>{sessionStorage.removeItem(c),l(0)})),!1)}}function g(){typeof PagefindUI<"u"&&(new PagefindUI({element:"#pagefind-ui",showSubResults:!0,showImages:!1,excerptLength:15,translations:{placeholder:"æœç´¢æ–‡ç« ...",clear_search:"æ¸…é™¤",load_more:"åŠ è½½æ›´å¤š",search_label:"æœç´¢æ­¤ç«™ç‚¹",filters_label:"ç­›é€‰",zero_results:"æœªæ‰¾åˆ°ç»“æœ [SEARCH_TERM]",many_results:"æ‰¾åˆ° [COUNT] ä¸ªç»“æœ [SEARCH_TERM]",one_result:"æ‰¾åˆ° [COUNT] ä¸ªç»“æœ [SEARCH_TERM]",alt_search:"æœªæ‰¾åˆ° [SEARCH_TERM] çš„ç»“æœã€‚æ˜¾ç¤º [DIFFERENT_TERM] çš„ç»“æœ",search_suggestion:"æœªæ‰¾åˆ° [SEARCH_TERM] çš„ç»“æœã€‚å°è¯•ä»¥ä¸‹æœç´¢ï¼š",searching:"æœç´¢ä¸­ [SEARCH_TERM]..."}}),setTimeout(()=>{const t=document.querySelector(".pagefind-ui__search-input");t instanceof HTMLElement&&t.focus()},100))}function u(){if(d)return;d=!0;const t=document.getElementById("search-button"),n=document.getElementById("search-dialog"),r=document.getElementById("close-search");if(!t||!n||!r)return;let i=sessionStorage.getItem(c)==="true";const o=async()=>{n.showModal(),document.body.style.overflow="hidden",i?setTimeout(()=>{const e=document.querySelector(".pagefind-ui__search-input");e instanceof HTMLElement&&e.focus()},100):await l()&&(i=!0)},s=()=>{n.close(),document.body.style.overflow=""},a=e=>{e.target===n&&s()},m=e=>{e.key==="Escape"&&n.open&&s()},f=e=>{(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),n.open?s():o())};t.addEventListener("click",o),r.addEventListener("click",s),n.addEventListener("click",a),document.addEventListener("keydown",m),document.addEventListener("keydown",f),document.addEventListener("astro:before-swap",()=>{t.removeEventListener("click",o),r.removeEventListener("click",s),n.removeEventListener("click",a),document.removeEventListener("keydown",m),document.removeEventListener("keydown",f),d=!1},{once:!0})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",u):u();document.addEventListener("astro:page-load",u);</script> <link href="/pagefind/pagefind-ui.css" rel="stylesheet">  </div> </div> </nav> </header>  <main id="main-content" data-pagefind-body class="main-content main-content--wide" data-astro-cid-sckkx6r4>  <div class="blog-post-container" data-astro-cid-wrgicudb> <article class="blog-post" data-astro-cid-wrgicudb> <header class="article-header" data-astro-cid-wrgicudb> <h1 data-astro-cid-wrgicudb>April 2021 newsletter</h1> <div class="article-meta" data-astro-cid-wrgicudb> <a href="https://gwern.net" target="_blank" rel="noopener noreferrer" class="source-tag" data-astro-cid-wrgicudb>gwern.net</a> <span class="separator" data-astro-cid-wrgicudb>Â·</span> <time data-astro-cid-wrgicudb>2021å¹´6æœˆ3æ—¥</time> </div> </header> <!-- ä½¿ç”¨æ¸…æ´—åçš„å®‰å…¨ HTML å†…å®¹ --> <div class="article-content app-prose" data-astro-cid-wrgicudb><p>April 2021â€™s <a href="https://www.gwern.net/newsletter/2021/04" target="_blank" rel="noopener noreferrer">Gwern.net</a> <a href="https://gwern.substack.com" target="_blank" rel="noopener noreferrer">newsletter</a> is now out; previous, <a href="https://www.gwern.net/newsletter/2021/03" target="_blank" rel="noopener noreferrer">March 2021</a> (<a href="https://www.gwern.net/tags/newsletter" target="_blank" rel="noopener noreferrer">archives</a>). This is a collation of links and summary of major changes, overlapping with my <a href="https://www.gwern.net/Changelog" target="_blank" rel="noopener noreferrer">Changelog</a>; brought to you by my donors on <a href="https://www.patreon.com/gwern" target="_blank" rel="noopener noreferrer">Patreon</a>.</p><h1>1 Writings</h1><ul><li><p><a href="https://www.gwern.net/Variables" target="_blank" rel="noopener noreferrer">Better Greek Variable Suggestions</a> (use Ï°, Ï‚, Ï…, Ï–, Î¥, Î, Î¹, Ï±, Ï‘, or Î  instead)</p></li></ul><h1>2 Links</h1><h2>2.1 AI</h2><ul><li><p><a href="https://arxiv.org/abs/1810.00825" target="_blank" rel="noopener noreferrer">â€œSet Transformer: A Framework for Attention-based Permutation-Invariant Neural Networksâ€</a>, Lee et al 2018; <a href="https://arxiv.org/abs/2103.03206#deepmind" target="_blank" rel="noopener noreferrer">â€œPerceiver: General Perception with Iterative Attentionâ€</a>, Jaegle et al 2021 (skinny Transformers applied recurrently; given reinvention, one might ask â€œis <a href="https://arxiv.org/abs/1706.03762#google" target="_blank" rel="noopener noreferrer">attention</a>, getting too much attention?â€, especially given how many Transformer tweaks <a href="https://arxiv.org/abs/2102.11972#google" target="_blank" rel="noopener noreferrer">donâ€™t pan out</a>  or have antecedents, indicating a gold rush? Probably not: if the  marginal return on this research direction had fallen below that of  competitors, we would see those neglected directions invade Transformer  topicsâ€”while we continue to see the reverse, and many applications as  yet untouched by all the new approaches, suggesting that we <em>still</em> donâ€™t pay enough attention)</p></li><li><p><a href="https://arxiv.org/abs/2103.04689" target="_blank" rel="noopener noreferrer">â€œZ-IL: Predictive Coding Can Do Exact Backpropagation on Any Neural Networkâ€</a>, Salvatori et al 2021 (scaling local learning rules to ImageNet AlexNet/Resnet &amp; ALE DRL at similar compute cost)</p></li><li><p><a href="https://arxiv.org/abs/1708.07120" target="_blank" rel="noopener noreferrer">â€œSuper-Convergence: Very Fast Training of Neural Networks Using Large Learning Ratesâ€</a>,  Smith &amp; Topin 2017 (the lingering mystery of super-convergence,  saving 50â€“90% compute with LRs as high as 20 (!): what is it, why does  it work only sometimes, is there any connection to <a href="https://www.gwern.net/docs/ai/2021-power.pdf#openai" target="_blank" rel="noopener noreferrer">grokking</a> &amp; can it work for large models like GPT-3 given the <a href="https://old.reddit.com/r/MachineLearning/comments/ba1wg5/d_thoughts_about_superconvergence_and/" target="_blank" rel="noopener noreferrer">tunneling hypothesis</a>?)</p></li><li><p><a href="http://www.offconvex.org/2021/04/07/ripvanwinkle/" target="_blank" rel="noopener noreferrer">â€œRip van Winkleâ€™s Razor, a Simple New Estimate for Adaptive Data Analysisâ€</a>  (an unusual approach to estimating generalizationâ€”by quantifying the  information-theoretic simplicity of all the powerful DL research  discoveries since 2012, into ~1 kilobyte. And yet, <em>what</em> a kilobyteâ€¦)</p></li><li><p><a href="https://github.com/golanlevin/AmbigrammaticFigures" target="_blank" rel="noopener noreferrer">â€œAmbigrammatic Figuresâ€</a>, Levin &amp; Huang 2020 (making horrifying StyleGAN faces that can be <a href="https://en.wikipedia.org/wiki/Ambigram" target="_blank" rel="noopener noreferrer">rotated 180Â°</a> by projection &amp; then <a href="https://www.gwern.net/Faces#reversing-stylegan-to-control-modify-images" target="_blank" rel="noopener noreferrer">gradient-ascent</a> towards an upside-down face)</p></li></ul><p><a href="https://old.reddit.com/r/mlscaling/" target="_blank" rel="noopener noreferrer">Matters Of Scale</a>:</p><ul><li><p><strong><a href="https://lair.lighton.ai/akronomicon/" target="_blank" rel="noopener noreferrer">Large Models</a></strong>:</p><ul><li><p>Congratulations to OpenAI on 1 year of GPT-3 &amp; OA API. Has it really only been a year?â€”it has truly exceeded expectations.</p></li><li><p><a href="https://en.wikipedia.org/wiki/Naver" target="_blank" rel="noopener noreferrer">Naver</a> announces 204b-parameter Korean-language NN, <a href="http://m.koreaherald.com/view.php?ud=20210525000824" target="_blank" rel="noopener noreferrer">â€œHyperCLOVAâ€</a>  (KO; unknown arch although apparently dense, or training-compute or  benchmark/loss performance; 650b token training dataset. Who knew Naver  was even trying? â€œAnd we are here as on a darkling plain / Swept with  confused alarms of struggle and flight, / Where ignorant armies clash by  night.â€)</p></li><li><p><a href="https://arxiv.org/abs/2104.12369#huawei" target="_blank" rel="noopener noreferrer">â€œPanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computationâ€</a>,  Zeng et al 2021 (Zh; Huaweiâ€™s GPT-3-200b prototype, trained on  indigenous Chinese GPU+DL stack; a partial replication, due to  incomplete training on ~43b tokens; the <a href="https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha#user-content-%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD" target="_blank" rel="noopener noreferrer">13b-parameter</a> model checkpoint has been released for download, and they are considering releasing the 200b-parameter modelâ€¦ <a href="https://chinai.substack.com/p/chinai-141-the-pangu-origin-story" target="_blank" rel="noopener noreferrer">Ding commentary</a>)</p></li><li><p>New ğ’ª(100b)-parameter Transformer models announced at Google I/O â€™2021: <a href="https://blog.google/technology/ai/lamda/" target="_blank" rel="noopener noreferrer">LaMDA</a> (EN; chatbot), <a href="https://blog.google/products/search/introducing-mum/" target="_blank" rel="noopener noreferrer">MUM</a> (multimodal multilingual search/translation/Q&amp;A)</p></li><li><p><a href="https://www.infoq.cn/article/EFIHo75sQsVqLvFTruKE#alibaba" target="_blank" rel="noopener noreferrer">â€œPLUGâ€</a> (Zh): a 27b parameter BERT-like Chinese language model, targeting 200b next (AliBaba followup to <a href="https://arxiv.org/abs/1908.04577#alibaba" target="_blank" rel="noopener noreferrer">StructBERT</a>/<a href="https://arxiv.org/abs/2004.07159#alibaba" target="_blank" rel="noopener noreferrer">PALM</a>)</p></li><li><p><a href="https://arxiv.org/abs/2105.13290" target="_blank" rel="noopener noreferrer">â€œCogView: Mastering Text-to-Image Generation via Transformersâ€</a>, Ding et al 2021 (another Chinese <a href="https://openai.com/blog/dall-e/" target="_blank" rel="noopener noreferrer">DALLÂ·E</a> clone, post-<a href="https://arxiv.org/abs/2103.00823#alibaba" target="_blank" rel="noopener noreferrer">M6</a>: <em>n</em> = <a href="https://wudaoai.cn/data-detail/1" target="_blank" rel="noopener noreferrer">30m text-image pairs</a>, 4b-parameter GPT, models to be released)</p></li><li><p><a href="https://arxiv.org/abs/2104.10157" target="_blank" rel="noopener noreferrer">â€œVideoGPT: Video Generation using VQ-VAE and Transformersâ€</a>, Yan et al 2021; <a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">â€œGODIVA: </a><em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">G</a></em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">enerating </a><em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">O</a></em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">pen-</a><em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">D</a></em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">oma</a><em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">I</a></em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">n </a><em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">V</a></em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">ideos from n</a><em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">A</a></em><a href="https://arxiv.org/abs/2104.14806#microsoft" target="_blank" rel="noopener noreferrer">tural Descriptionsâ€</a>, Wu et al 2021 (DALLÂ·E for video on Howto100M: <a href="https://arxiv.org/abs/1906.00446#deepmind" target="_blank" rel="noopener noreferrer">VQ-VAE</a> + sparse attention)</p></li><li><p><a href="https://arxiv.org/abs/2104.04473#nvidia" target="_blank" rel="noopener noreferrer">â€œEfficient Large-Scale Language Model Training on GPU Clustersâ€</a>, Narayanan et al 2021 (Nvidia <a href="https://github.com/nvidia/megatron-lm" target="_blank" rel="noopener noreferrer">â€˜Megatron-LMâ€™ software</a> for scaling up to 3072 A100 GPUs; allows 1t-parameter models at 502 petaFLOP/s or 50% efficiency, cf TPU rival, <a href="https://arxiv.org/abs/2105.04663#google" target="_blank" rel="noopener noreferrer">GSPMD</a>, and note <a target="_blank" rel="noopener noreferrer">Patterson et al 2021</a> estimates GPT-3 at ~3.5m V100 GPU-hours, so OA got ~20% efficiency?); <a href="https://www.youtube.com/watch?v=eAn_oiZwUXA&amp;t=2998s" target="_blank" rel="noopener noreferrer">â€œWe expect to see multi-trillion-parameter models by next year, and 100 trillion+ parameter models by 2023â€</a> â€”Nvidia CEO <a href="https://en.wikipedia.org/wiki/Jensen_Huang" target="_blank" rel="noopener noreferrer">Jensen Huang</a> (<a href="https://www.gwern.net/docs/ai/2021-04-12-jensenhuang-gtc2021keynote-eAn_oiZwUXA.en.vtt.txt" target="_blank" rel="noopener noreferrer">subtitles</a>)</p></li><li><p>Mixture-Of-Experts:</p><ul><li><p><a href="https://en.pingwest.com/a/8693" target="_blank" rel="noopener noreferrer">BAAIâ€™s â€œWudao Wensuâ€: 1.75-trillion parameters &amp; multimodal!</a> (<a href="https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/" target="_blank" rel="noopener noreferrer">prologue</a>)</p></li><li><p><a href="https://arxiv.org/abs/2105.15082#alibaba" target="_blank" rel="noopener noreferrer">â€œExploring Sparse Expert Models and Beyondâ€</a>, Yang et al 2021 (1t-parameter hierarchical Switch Transformer trained on 480 V100 GPUs)</p></li></ul></li></ul></li><li><p><strong><a href="https://arxiv.org/abs/1911.08265#deepmind" target="_blank" rel="noopener noreferrer">MuZero</a></strong>:</p><ul><li><p><a href="https://arxiv.org/abs/2104.06294#deepmind" target="_blank" rel="noopener noreferrer">â€œMuZero Unplugged: Online and Offline Reinforcement Learning by Planning with a Learned Modelâ€</a>, Schrittwieser et al 2021 (Reanalyze+MuZero; <a href="https://www.gwern.net/images/ai/2021-schrittwieser-figure1-mspacmanmuzerologrewardscaling.png" target="_blank" rel="noopener noreferrer">smooth log-scaling</a> of <em>Ms.Â Pacman</em> reward with sample size, 107â€“1010, showing that DRL for arcade games parallels board games)</p></li><li><p><a href="https://sites.google.com/berkeley.edu/decision-transformer" target="_blank" rel="noopener noreferrer">â€œDecision Transformer: Reinforcement Learning via Sequence Modelingâ€</a>, Chen et al 2021</p></li><li><p><a href="https://arxiv.org/abs/2104.06303#deepmind" target="_blank" rel="noopener noreferrer">â€œSampled MuZero: Learning and Planning in Complex Action Spacesâ€</a>, Hubert et al 2021 (MuZero for continuous domains: DM Control Suite/Real-World RL Suite); <a href="https://arxiv.org/abs/2006.07430" target="_blank" rel="noopener noreferrer">â€œContinuous Control for Searching and Planning with a Learned Modelâ€</a>, Yang et al 2020</p></li><li><p><a href="https://arxiv.org/abs/2104.06159" target="_blank" rel="noopener noreferrer">â€œMuesli: Combining Improvements in Policy Optimizationâ€</a>, Hessel et al 2020 (catching up with original MuZero)</p></li><li><p><a href="https://arxiv.org/abs/2102.12924" target="_blank" rel="noopener noreferrer">â€œVisualizing MuZero Modelsâ€</a>, de Vries et al 2021 (reimplementing &amp; introspecting a MuZero)</p></li></ul></li><li><p><a href="https://arxiv.org/abs/2104.03113" target="_blank" rel="noopener noreferrer">â€œScaling Scaling Laws with Board Gamesâ€</a>, <a href="https://andyljones.com/" target="_blank" rel="noopener noreferrer">Jones</a> 2021 (AlphaZero/<a href="https://en.wikipedia.org/wiki/Hex_(board_game)" target="_blank" rel="noopener noreferrer">Hex</a>: <a href="https://www.gwern.net/notes/Faster" target="_blank" rel="noopener noreferrer">highly-optimized</a> GPU implementation enables showing <a href="https://www.gwern.net/notes/Scaling" target="_blank" rel="noopener noreferrer">smooth scaling</a>  across 6 OOM of computeâ€”2Ã— FLOPS = 66% victory; amortization of  training â†’ runtime tree-search, where 10Ã— training = 15Ã— runtime)</p></li><li><p><a href="https://christina.kim/2021/04/11/scaling-laws-for-language-transfer-learning/#openai" target="_blank" rel="noopener noreferrer">â€œScaling Laws for Language Transfer Learningâ€</a>, Christina Kim (<a href="https://arxiv.org/abs/2102.01293#openai" target="_blank" rel="noopener noreferrer">Hernandez et al 2021</a> followup: smooth scaling for En â†’ De/Es/Zh)</p></li><li><p><a href="https://arxiv.org/abs/2104.10350#google" target="_blank" rel="noopener noreferrer">â€œCarbon Emissions and Large Neural Network Trainingâ€</a>,  Patterson et al 2021 (â€œâ€¦choice of DNN/datacenter/processor can reduce  the carbon footprint up to ~100â€“1000Ã—. These large factors make  retroactive estimates difficult.â€)</p></li><li><p><a href="https://arxiv.org/abs/2104.07705" target="_blank" rel="noopener noreferrer">â€œHow to Train BERT with an Academic Budgetâ€</a>, Izsak et al 2021 (<a href="https://arxiv.org/abs/1810.04805#google" target="_blank" rel="noopener noreferrer">BERT</a> in 8 GPU-daysâ€”R&amp;D iteration allows finding efficiency; thereâ€™s nothing so expensive as demanding research be cheap.^1^)</p></li></ul><h2>2.2 Genetics</h2><p>Everything Is Heritable:</p><ul><li><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6818669/" target="_blank" rel="noopener noreferrer">â€œPrecision exercise medicine: understanding exercise response variabilityâ€</a>,  Ross et al 2019 (â€œlarge individual differences in CRF response (range:  âˆ’33% to +118%) have been observed across the 8 exercise training studies  independent of exercise durationâ€â€”nothing in psychology, or medicine,  makes sense except in the light of individual differencesâ€¦)</p></li></ul><p>Recent Evolution:</p><ul><li><p><a href="https://academic.oup.com/mbe/advance-article/doi/10.1093/molbev/msab147/6277411" target="_blank" rel="noopener noreferrer">â€œAnalysis of genomic DNA from medieval plague victims suggests long-term effect of </a><em><a href="https://academic.oup.com/mbe/advance-article/doi/10.1093/molbev/msab147/6277411" target="_blank" rel="noopener noreferrer">Yersinia pestis</a></em><a href="https://academic.oup.com/mbe/advance-article/doi/10.1093/molbev/msab147/6277411" target="_blank" rel="noopener noreferrer"> on human immunity genesâ€</a>, Immel et al 2021</p></li></ul><p>Engineering:</p><ul><li><p><a href="https://biohackinfo.com/news-china-gene-editing-criminal-law-article-336-march-2021/" target="_blank" rel="noopener noreferrer">â€œChina officially bans CRISPR babies, human clones and animal-human hybridsâ€</a>? (another blow to attempts to project fears &amp; fantasies onto China)</p></li></ul><h2>2.3 Politics/Religion</h2><ul><li><p><em><a href="https://www.nap.edu/catalog/25762/reflecting-sunlight-recommendations-for-solar-geoengineering-research-and-research-governance" target="_blank" rel="noopener noreferrer">Reflecting Sunlight: Recommendations for Solar Geoengineering Research and Research Governance</a></em>, National Academies 2021 (<a href="https://www.nytimes.com/2021/03/25/climate/geoengineering-sunlight.html" target="_blank" rel="noopener noreferrer">media</a>)</p></li><li><p><a href="https://www.gwern.net/docs/sociology/2020-muralidharan.pdf" target="_blank" rel="noopener noreferrer">â€œImproving Public Sector Management at Scale? Experimental Evidence on School Governance Indiaâ€</a>, Muralidharan &amp; Singh 2020</p></li><li><p><a href="https://www.gwern.net/docs/fiction/2012-mason.pdf" target="_blank" rel="noopener noreferrer">â€œJay-Zâ€™s </a><em><a href="https://www.gwern.net/docs/fiction/2012-mason.pdf" target="_blank" rel="noopener noreferrer">99 Problems</a></em><a href="https://www.gwern.net/docs/fiction/2012-mason.pdf" target="_blank" rel="noopener noreferrer">, Verse 2: A Close Reading with 4th Amendment Guidance for Cops and Perpsâ€</a>, Mason 2012</p></li></ul><h2>2.4 Psychology/Biology</h2><ul><li><p><a href="https://www.gwern.net/docs/longevity/2021-wiley.pdf" target="_blank" rel="noopener noreferrer">â€œOxylipin biosynthesis reinforces cellular senescence and allows detection of senolysisâ€</a>, Wiley et al 2021</p></li><li><p><a href="https://www.nytimes.com/2019/02/26/magazine/psychics-skeptics-facebook.html" target="_blank" rel="noopener noreferrer">â€œInside the Secret Sting Operations to Expose Celebrity Psychicsâ€</a></p></li><li><p><a href="https://www.gwern.net/docs/catnip/2021-smith.pdf" target="_blank" rel="noopener noreferrer">â€œIf I fits I sits: A citizen science investigation into illusory contour susceptibility in domestic cats (</a><em><a href="https://www.gwern.net/docs/catnip/2021-smith.pdf" target="_blank" rel="noopener noreferrer">Felis silvestris catus</a></em><a href="https://www.gwern.net/docs/catnip/2021-smith.pdf" target="_blank" rel="noopener noreferrer">)â€</a>, Smith et al 2021</p></li><li><p><a href="https://www.gwern.net/docs/biology/2005-paxton.pdf" target="_blank" rel="noopener noreferrer">â€œCetaceans,  sex and sea serpents: an analysis of the Egede accounts of a â€˜most  dreadful monsterâ€™ seen off the coast of Greenland in 1734â€</a>, Paxton et al 2005 (is that a legendary cryptid in your pocket, or are you just happy to see me?)</p></li><li><p><a href="https://www.gwern.net/docs/psychology/writing/2020-reilly.pdf" target="_blank" rel="noopener noreferrer">â€œBuilding the perfect curse word: A psycholinguistic investigation of the form and meaning of taboo wordsâ€</a>, Reilly et al 2020</p></li><li><p><a href="https://en.wikipedia.org/wiki/Tarrare" target="_blank" rel="noopener noreferrer">Tarrare</a></p></li></ul><h2>2.5 Technology</h2><ul><li><p><a href="https://arxiv.org/abs/2103.07487" target="_blank" rel="noopener noreferrer">â€œHow Developers Choose Namesâ€</a>,  Feitelson et al 2021 (â€œAnother example concerned the function  â€˜arrangeFilesByName(files)â€™. When asked the return valueâ€¦one suggested  the number of files reorderedâ€)</p></li><li><p><a href="https://arxiv.org/abs/2004.02504" target="_blank" rel="noopener noreferrer">â€œBringing GNU Emacs to Native Codeâ€</a>,  Corallo et al 2020 (using libgccjit to make Emacs 2.3Ã— to 42Ã— faster;  gccemacs has been merged into Emacs HEAD &amp; will be available soon)</p></li><li><p><a href="https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/" target="_blank" rel="noopener noreferrer">â€œHosting SQLite databases on Github Pages (or any static file hoster)â€</a> (a revolution in static website technology: eg running a query <a href="https://nitter.cc/simonw/status/1388933800445452290" target="_blank" rel="noopener noreferrer">need download only 54kb of a 670MB database</a>; fulltext site search is just the beginning of the possibilities of this clever use of <a href="https://en.wikipedia.org/wiki/Byte_serving" target="_blank" rel="noopener noreferrer">range requests</a>)</p></li><li><p><a href="https://www.coderelay.io/fontemon.html" target="_blank" rel="noopener noreferrer">â€œ</a><em><a href="https://www.coderelay.io/fontemon.html" target="_blank" rel="noopener noreferrer">Fontemon</a></em><a href="https://www.coderelay.io/fontemon.html" target="_blank" rel="noopener noreferrer">: Worldâ€™s first video game in a font!â€</a> (a <em>Pokemon</em>-like CYOA <a href="https://github.com/mmulet/code-relay/blob/main/markdown/HowIDidIt.md" target="_blank" rel="noopener noreferrer">implemented as an OpenType font file</a>; play in browser or text editorâ€”still not quite <a href="https://www.gwern.net/Turing-complete" target="_blank" rel="noopener noreferrer">Turing-complete</a> but definitely the most impressive thing implemented in a font so far)</p><ul><li><p><em>Fontemon</em> is by far the highlight of <a href="http://sigbovik.org/2021/proceedings.pdf" target="_blank" rel="noopener noreferrer">SIGBOVIK 2021</a>; but also worth noting: <a href="http://sigbovik.org/2021/proceedings.pdf#page=8" target="_blank" rel="noopener noreferrer">â€œBack to Square One: Superhuman Performance in Chutes and Ladders Through Deep Neural Networks and Tree Searchâ€</a> Â· <a href="http://sigbovik.org/2021/proceedings.pdf#page=83" target="_blank" rel="noopener noreferrer">â€œDeep Deterministic Policy Gradient Boosted Decision Treesâ€</a> Â· <a href="http://sigbovik.org/2021/proceedings.pdf#page=126" target="_blank" rel="noopener noreferrer">â€œLowestcase and uppestcase letters: Advances in derp learningâ€</a> Â· <a href="http://sigbovik.org/2021/proceedings.pdf#page=167" target="_blank" rel="noopener noreferrer">â€œopenCHEAT: Computationally Helped Error bar Approximation Toolâ€”Kick-starting Science 4.0â€</a> Â· <a href="http://sigbovik.org/2021/proceedings.pdf#page=216" target="_blank" rel="noopener noreferrer">â€œThe Newcomb-Benford Law, Applied to Binary Data: An Empirical and Theoretic Analysisâ€</a> Â· <a href="http://sigbovik.org/2021/proceedings.pdf#page=252" target="_blank" rel="noopener noreferrer">â€œInverted Code Theory: Manipulating Program Entropyâ€</a> (<em><a href="https://en.wikipedia.org/wiki/Tenet_(film)" target="_blank" rel="noopener noreferrer">Tenet</a></em> fans onlyâ€”possibly inferior to <a href="http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html" target="_blank" rel="noopener noreferrer">Moravec 1991</a>?) Â· <a href="http://sigbovik.org/2021/proceedings.pdf#page=282" target="_blank" rel="noopener noreferrer">â€œBuild your own 8-bit busy beaver on a breadboard!â€</a></p></li></ul><p>Incidentally, itâ€™s curious that while STEM fields have entire annual issues, journals, &amp; conferences devoted to satire (<a href="http://sigbovik.org/" target="_blank" rel="noopener noreferrer">SIGBOVIK</a>; Arxiv April Fools papers like <a href="https://arxiv.org/abs/1703.10987" target="_blank" rel="noopener noreferrer">Garfinkel et al 2017</a>; <a href="https://www108.lamp.le.ac.uk/ojs1/index.php/pst/issue/archive" target="_blank" rel="noopener noreferrer">Special Topics</a>; the <a href="https://www.bmj.com/about-bmj/resources-authors/article-types/christmas-issue" target="_blank" rel="noopener noreferrer">BMJ Christmas issue</a>; the <a href="https://en.wikipedia.org/wiki/Ig_Nobel_Prize" target="_blank" rel="noopener noreferrer">Ig Nobel Prizes</a> &amp; <a href="https://bahfest.com/" target="_blank" rel="noopener noreferrer">BAHFest</a>), after asking in several places, I have found no instances in the humanities. (I know of many entertaining <em>papers</em>, like <a href="https://www.gwern.net/docs/philo/2008-sinhababu.pdf" target="_blank" rel="noopener noreferrer">Sinhababu 2008</a> on waifus, but no <em>regular organized</em> publication, with the possible exception of the annual <a href="https://en.wikipedia.org/wiki/Latke%E2%80%93Hamantash_Debate" target="_blank" rel="noopener noreferrer">â€œLatke-Hamantash Debateâ€</a>.)</p></li></ul><h2>2.6 Economics</h2><ul><li><p><a href="https://www.gwern.net/docs/statistics/decision/2006-thorp.pdf" target="_blank" rel="noopener noreferrer">â€œThe Kelly Criterion in Blackjack Sports Betting, and the Stock Marketâ€</a>, Thorp 2006</p></li><li><p><a href="https://marginalrevolution.com/marginalrevolution/2016/10/performance-pay-nobel.html" target="_blank" rel="noopener noreferrer">â€œThe Performance Pay Nobelâ€</a> (CEO pay as <a href="https://www.gwern.net/Backstop" target="_blank" rel="noopener noreferrer">blackbox optimization problem</a>)</p></li><li><p><a href="https://www.gwern.net/docs/economics/2008-josephson.pdf" target="_blank" rel="noopener noreferrer">â€œThe Oceanâ€™s Hot Dog: The Development of the Fish Stickâ€</a>,  Kelly 2008 (out of nostalgia, I bought some fish sticks for the first  time in decades; better than I remembered, even if I had no <a href="https://en.wikipedia.org/wiki/Tartar_sauce" target="_blank" rel="noopener noreferrer">tartar</a> handy)</p></li></ul><h2>2.7 Philosophy</h2><ul><li><p><a href="https://www.gwern.net/docs/culture/2007-shiner.pdf" target="_blank" rel="noopener noreferrer">â€œThe Aesthetics of Smelly Artâ€</a>, Shiner &amp; Kriskovets 2007; <a href="https://www.gwern.net/docs/culture/2019-kraft.pdf" target="_blank" rel="noopener noreferrer">â€œThe Odor Value Concept in the Formal Analysis of Olfactory Artâ€</a>, Kraft 2019; <a href="https://qualiacomputing.com/2020/02/21/perfumery-as-an-art-form/" target="_blank" rel="noopener noreferrer">â€œPerfumery as an art formâ€</a>/<a href="https://qualiacomputing.com/2020/08/14/qualia-research-diary-scents/" target="_blank" rel="noopener noreferrer">notes</a>, Qualia Computing 2020 (more: manufacturing: <a href="https://www.newyorker.com/magazine/2005/03/14/scent-nile" target="_blank" rel="noopener noreferrer">â€œThe Scent of the Nile: Jean-Claude Ellena creates a new perfumeâ€</a>; human smell is better than you think: <a href="https://www.gwern.net/docs/psychology/2006-porter.pdf" target="_blank" rel="noopener noreferrer">â€œMechanisms of Scent-tracking in Humansâ€</a>, Porter et al 2006 (<a href="https://www.gwern.net/images/psychology/2006-porter-humanscenttracking-41593_2007_bfnn1819_moesm2_esm.mp4" target="_blank" rel="noopener noreferrer">video</a>; see also <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5512720/" target="_blank" rel="noopener noreferrer">â€œPoor Human Olfaction is a 19th Century Mythâ€</a>, McGann 2017); <a href="https://www.pnas.org/content/109/49/19959.full" target="_blank" rel="noopener noreferrer">olfactory white</a>; <em><a href="https://en.wikipedia.org/wiki/K%C5%8Dd%C5%8D" target="_blank" rel="noopener noreferrer">KÅdÅ</a></em>, which unexpectedly appears in <a href="https://www.gwern.net/docs/cs/2005-knuth-taocp-v4-prefascicle4b.pdf#page=22" target="_blank" rel="noopener noreferrer">Knuth</a>. <a href="https://threadreaderapp.com/thread/1357071738731814912.html" target="_blank" rel="noopener noreferrer">C. Thi Nguyen</a>â€™s description of the more bizarre &amp; avant-garde perfumes made me curious enough to nose around &amp; order 39 <a href="https://www.luckyscent.com/" target="_blank" rel="noopener noreferrer">LuckyScent</a> samplers.)</p></li></ul><h2>2.8 Miscellaneous</h2><ul><li><p><a href="https://en.wikipedia.org/wiki/Bog_butter" target="_blank" rel="noopener noreferrer">Bog butter</a></p></li><li><p><a href="https://en.wikipedia.org/wiki/Sarah_Bernhardt" target="_blank" rel="noopener noreferrer">Sarah Bernhardt</a> (Lions. Lots of lions.)</p></li></ul><div><hr /></div><ol><li><p>Another thought, looking at <a href="https://bls.gov/news.release/ecec.nr0.htm" target="_blank" rel="noopener noreferrer">â€˜Employer Costs for Employee Compensationâ€™</a> (<a href="https://bls.gov/news.release/archives/ecec_031986.pdf" target="_blank" rel="noopener noreferrer">PDF</a>):</p><ol><li><p>â€œMooreâ€™s Lawâ€: the cost of a transistor halves every ~19 months;</p></li><li><p>â€œAnti-Mooreâ€™s Lawâ€: the cost of a synapse doubles every ~119 years.</p></li></ol></li></ol></div> <footer class="article-footer" data-astro-cid-wrgicudb> <div class="action-row" data-astro-cid-wrgicudb> <a href="https://gwern.substack.com/p/april-2021-newsletter" target="_blank" rel="noopener noreferrer" class="read-original-btn" data-astro-cid-wrgicudb>
é˜…è¯»åŸæ–‡ â†—
</a> </div> <div class="back-to-list" data-astro-cid-wrgicudb> <a href="/reading-list" class="back-link" data-astro-cid-wrgicudb>â† è¿”å›è®¢é˜…åˆ—è¡¨</a> </div> </footer> </article> </div>  </main> <footer class="site-footer" aria-label="Site footer" data-astro-cid-sz7xmlte> <div class="footer-content" data-astro-cid-sz7xmlte> <p class="footer-text" data-astro-cid-sz7xmlte>
&copy; 2026 AstroBlog
</p> <p class="footer-text" data-astro-cid-sz7xmlte>
Built with  <a href="https://astro.build/" target="_blank" rel="noopener noreferrer" class="footer-link" data-astro-cid-sz7xmlte>
Astro
</a> </p> </div> </footer>  </body></html> 