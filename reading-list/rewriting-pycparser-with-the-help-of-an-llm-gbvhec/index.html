<!DOCTYPE html><html lang="zh-CN" data-astro-cid-sckkx6r4> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.17.1"><meta name="description" content="pycparser 是我使用最广泛的开源项目之一（每天从 PyPI [1] 下载量约 2000 万次）。它是一个纯 Python 的 C 语言解析器，生成的 AST 灵感来自 Python 自身的 AST。直到"><meta http-equiv="Content-Security-Policy" content="default-src 'self'; style-src 'self' 'unsafe-inline'; script-src 'self' 'unsafe-inline'; img-src 'self' data: https:; connect-src 'self'; font-src 'self' data:;"><link rel="canonical" href="https://blog.yuyins.com/reading-list/rewriting-pycparser-with-the-help-of-an-llm-gbvhec/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://blog.yuyins.com/reading-list/rewriting-pycparser-with-the-help-of-an-llm-gbvhec/"><meta property="og:title" content="借助 LLM 重写 pycparser"><meta property="og:description" content="pycparser 是我使用最广泛的开源项目之一（每天从 PyPI [1] 下载量约 2000 万次）。它是一个纯 Python 的 C 语言解析器，生成的 AST 灵感来自 Python 自身的 AST。直到"><meta property="og:image" content="https://blog.yuyins.com/favicon.svg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://blog.yuyins.com/reading-list/rewriting-pycparser-with-the-help-of-an-llm-gbvhec/"><meta property="twitter:title" content="借助 LLM 重写 pycparser"><meta property="twitter:description" content="pycparser 是我使用最广泛的开源项目之一（每天从 PyPI [1] 下载量约 2000 万次）。它是一个纯 Python 的 C 语言解析器，生成的 AST 灵感来自 Python 自身的 AST。直到"><meta property="twitter:image" content="https://blog.yuyins.com/favicon.svg"><title>借助 LLM 重写 pycparser</title><!-- Theme and color scheme script (runs before page loads to prevent flash) --><script>
			// 初始化配色方案 - 默认使用 stone-amber
			const colorScheme = localStorage.getItem('colorScheme') || 'stone-amber';
			document.documentElement.setAttribute('data-color', colorScheme);

			// 强制使用浅色主题
			document.documentElement.setAttribute('data-theme', 'light');
		</script><link rel="stylesheet" href="/_astro/_slug_.Da6PdEKR.css">
<style>.blog-post-container[data-astro-cid-wrgicudb]{width:100%;margin:0 auto;padding:2rem 0}.blog-post[data-astro-cid-wrgicudb]{width:100%;min-width:0;max-width:42rem;margin:0 auto}.article-header[data-astro-cid-wrgicudb]{margin-bottom:2rem;padding-bottom:1rem;border-bottom:1px solid var(--border)}.article-header[data-astro-cid-wrgicudb] h1[data-astro-cid-wrgicudb]{font-size:2rem;line-height:1.3;margin-bottom:1rem;font-weight:700;color:var(--foreground);word-break:break-word}.article-meta[data-astro-cid-wrgicudb]{display:flex;align-items:center;gap:.5rem;font-size:.875rem;color:var(--muted-foreground)}.source-tag[data-astro-cid-wrgicudb]{background-color:var(--muted);color:var(--foreground);padding:.125rem .5rem;border-radius:9999px;font-weight:500;font-size:.75rem;text-decoration:none;transition:opacity .2s}.source-tag[data-astro-cid-wrgicudb]:hover{opacity:.8}.separator[data-astro-cid-wrgicudb]{color:var(--border)}.article-content[data-astro-cid-wrgicudb]{line-height:1.8;margin-bottom:3rem;font-size:1.0625rem;color:var(--foreground)}.article-content[data-astro-cid-wrgicudb] h2{margin-top:2rem;margin-bottom:1rem;font-size:1.5rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] h3{margin-top:1.5rem;margin-bottom:.75rem;font-size:1.25rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] p{margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] a{color:var(--accent);text-decoration:underline;text-underline-offset:2px}.article-content[data-astro-cid-wrgicudb] img{max-width:100%;height:auto;border-radius:.5rem;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] blockquote{border-left:4px solid var(--border);padding-left:1rem;margin:1.5rem 0;color:var(--muted-foreground);font-style:italic}.article-content[data-astro-cid-wrgicudb] pre{background:var(--muted);padding:1rem;border-radius:.5rem;overflow-x:auto;font-family:monospace;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] ul,.article-content[data-astro-cid-wrgicudb] ol{padding-left:1.5rem;margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] li{margin-bottom:.5rem}.article-footer[data-astro-cid-wrgicudb]{padding-top:2rem;border-top:1px solid var(--border);display:flex;flex-direction:column;gap:1.5rem;align-items:center}.action-row[data-astro-cid-wrgicudb]{display:flex;justify-content:center}.read-original-btn[data-astro-cid-wrgicudb]{display:inline-flex;align-items:center;gap:.5rem;padding:.75rem 1.5rem;background-color:var(--foreground);color:var(--background);border-radius:.5rem;font-weight:500;text-decoration:none;transition:opacity .2s}.read-original-btn[data-astro-cid-wrgicudb]:hover{opacity:.9}.back-to-list[data-astro-cid-wrgicudb]{text-align:center}.back-link[data-astro-cid-wrgicudb]{color:var(--muted-foreground);text-decoration:none;font-size:.875rem;transition:color .2s}.back-link[data-astro-cid-wrgicudb]:hover{color:var(--foreground)}
</style></head> <body data-astro-cid-sckkx6r4> <a id="skip-to-content" href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:top-4 focus:left-4 focus:z-50 focus:px-4 focus:py-2 focus:bg-accent focus:text-background" data-astro-cid-sckkx6r4>Skip to content</a> <header class="header" data-astro-cid-3ef6ksr2> <nav class="header-nav" aria-label="Main navigation" data-astro-cid-3ef6ksr2> <a href="/" class="header-logo" data-astro-cid-3ef6ksr2>
AstroBlog
</a> <div class="header-links" data-astro-cid-3ef6ksr2> <ul class="nav-list" data-astro-cid-3ef6ksr2> <li data-astro-cid-3ef6ksr2> <a href="/" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 文章 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/category" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 分类 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/reading-list" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 订阅 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/about" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 关于 </a> </li> </ul> <div class="header-actions" data-astro-cid-3ef6ksr2> <div id="search" data-astro-cid-otpdt6jm> <button id="search-button" class="search-toggle" aria-label="打开搜索" title="搜索 (⌘K)" data-astro-cid-otpdt6jm> <svg class="search-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <circle cx="11" cy="11" r="7" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></circle> <path d="M20 20L16.5 16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></path> </svg> </button> <dialog id="search-dialog" class="search-modal" data-astro-cid-otpdt6jm> <div class="modal-content" data-astro-cid-otpdt6jm> <div class="modal-header" data-astro-cid-otpdt6jm> <h2 class="modal-title" data-astro-cid-otpdt6jm>搜索文章</h2> <button id="close-search" class="close-button" aria-label="关闭搜索" data-astro-cid-otpdt6jm> <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <path d="M18 6L6 18M6 6l12 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-otpdt6jm></path> </svg> </button> </div> <div id="pagefind-ui" data-astro-cid-otpdt6jm></div> </div> </dialog> </div> <script type="module">let d=!1;const c="pagefind-loaded";async function l(t=0){if(sessionStorage.getItem(c)==="true")return g(),!0;const r=document.getElementById("pagefind-ui");if(!r)return!1;r.innerHTML='<div style="padding: 2rem; text-align: center; color: var(--muted-foreground);">加载中...</div>';try{return await new Promise((o,s)=>{const a=document.createElement("script");a.src="/pagefind/pagefind-ui.js",a.onload=o,a.onerror=s,document.head.appendChild(a)}),g(),sessionStorage.setItem(c,"true"),!0}catch(i){return console.error("Failed to load search:",i),t<2?(console.log(`Retrying search load... (${t+1}/2)`),await new Promise(o=>setTimeout(o,1e3)),l(t+1)):(r&&(r.innerHTML=`
          <div style="padding: 2rem; text-align: center;">
            <p style="color: var(--muted-foreground); margin-bottom: 1rem;">搜索功能加载失败</p>
            <button id="retry-search" style="padding: 0.5rem 1rem; background: var(--accent); color: var(--accent-foreground); border: none; border-radius: 0.375rem; cursor: pointer;">
              重试
            </button>
          </div>
        `,document.getElementById("retry-search")?.addEventListener("click",()=>{sessionStorage.removeItem(c),l(0)})),!1)}}function g(){typeof PagefindUI<"u"&&(new PagefindUI({element:"#pagefind-ui",showSubResults:!0,showImages:!1,excerptLength:15,translations:{placeholder:"搜索文章...",clear_search:"清除",load_more:"加载更多",search_label:"搜索此站点",filters_label:"筛选",zero_results:"未找到结果 [SEARCH_TERM]",many_results:"找到 [COUNT] 个结果 [SEARCH_TERM]",one_result:"找到 [COUNT] 个结果 [SEARCH_TERM]",alt_search:"未找到 [SEARCH_TERM] 的结果。显示 [DIFFERENT_TERM] 的结果",search_suggestion:"未找到 [SEARCH_TERM] 的结果。尝试以下搜索：",searching:"搜索中 [SEARCH_TERM]..."}}),setTimeout(()=>{const t=document.querySelector(".pagefind-ui__search-input");t instanceof HTMLElement&&t.focus()},100))}function u(){if(d)return;d=!0;const t=document.getElementById("search-button"),n=document.getElementById("search-dialog"),r=document.getElementById("close-search");if(!t||!n||!r)return;let i=sessionStorage.getItem(c)==="true";const o=async()=>{n.showModal(),document.body.style.overflow="hidden",i?setTimeout(()=>{const e=document.querySelector(".pagefind-ui__search-input");e instanceof HTMLElement&&e.focus()},100):await l()&&(i=!0)},s=()=>{n.close(),document.body.style.overflow=""},a=e=>{e.target===n&&s()},m=e=>{e.key==="Escape"&&n.open&&s()},f=e=>{(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),n.open?s():o())};t.addEventListener("click",o),r.addEventListener("click",s),n.addEventListener("click",a),document.addEventListener("keydown",m),document.addEventListener("keydown",f),document.addEventListener("astro:before-swap",()=>{t.removeEventListener("click",o),r.removeEventListener("click",s),n.removeEventListener("click",a),document.removeEventListener("keydown",m),document.removeEventListener("keydown",f),d=!1},{once:!0})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",u):u();document.addEventListener("astro:page-load",u);</script> <link href="/pagefind/pagefind-ui.css" rel="stylesheet">  </div> </div> </nav> </header>  <main id="main-content" data-pagefind-body class="main-content main-content--wide" data-astro-cid-sckkx6r4>  <div class="blog-post-container" data-astro-cid-wrgicudb> <article class="blog-post" data-astro-cid-wrgicudb> <header class="article-header" data-astro-cid-wrgicudb> <h1 data-astro-cid-wrgicudb>借助 LLM 重写 pycparser</h1> <div class="article-meta" data-astro-cid-wrgicudb> <a href="https://eli.thegreenplace.net" target="_blank" rel="noopener noreferrer" class="source-tag" data-astro-cid-wrgicudb>eli.thegreenplace.net</a> <span class="separator" data-astro-cid-wrgicudb>·</span> <time data-astro-cid-wrgicudb>2026年2月5日</time> </div> </header> <!-- 使用清洗后的安全 HTML 内容 --> <div class="article-content app-prose" data-astro-cid-wrgicudb><p><a href="https://github.com/eliben/pycparser" target="_blank" rel="noopener noreferrer">pycparser</a> is my most widely used open
source project (with ~20M daily downloads from PyPI <a href="#footnote-1" target="_blank" rel="noopener noreferrer">[1]</a>). It's a pure-Python
parser for the C programming language, producing ASTs inspired by <a href="https://docs.python.org/3/library/ast.html" target="_blank" rel="noopener noreferrer">Python's
own</a>. Until very recently, it's
been using <a href="https://www.dabeaz.com/ply/ply.html" target="_blank" rel="noopener noreferrer">PLY: Python Lex-Yacc</a> for
the core parsing.</p>
<p>In this post, I'll describe how I collaborated with an LLM coding agent (Codex)
to help me rewrite pycparser to use a hand-written recursive-descent parser and
remove the dependency on PLY. This has been an interesting experience and the
post contains lots of information and is therefore quite long; if you're just
interested in the final result, check out the latest code of pycparser - the
main branch already has the new implementation.</p>
<img alt="meme picture saying &quot;can't come to bed because my AI agent produced something slightly wrong&quot;" src="https://eli.thegreenplace.net/images/2026/cantcometobed.png" />
<div>
<h2>The issues with the existing parser implementation</h2>
<p>While pycparser has been working well overall, there were a number of nagging
issues that persisted over years.</p>
<div>
<h3>Parsing strategy: YACC vs. hand-written recursive descent</h3>
<p>I began working on pycparser in 2008, and back then using a YACC-based approach
for parsing a whole language like C seemed like a no-brainer to me. Isn't this
what everyone does when writing a serious parser? Besides, the K&amp;R2 book
famously carries the entire grammar of the C99 language in an appendix - so it
seemed like a simple matter of translating that to PLY-yacc syntax.</p>
<p>And indeed, it wasn't <em>too</em> hard, though there definitely were some complications
in building the ASTs for declarations (C's <a href="https://eli.thegreenplace.net/2008/10/18/implementing-cdecl-with-pycparser" target="_blank" rel="noopener noreferrer">gnarliest part</a>).</p>
<p>Shortly after completing pycparser, I got more and more interested in compilation
and started learning about the different kinds of parsers more seriously. Over
time, I grew convinced that <a href="https://eli.thegreenplace.net/tag/recursive-descent-parsing" target="_blank" rel="noopener noreferrer">recursive descent</a> is the way to
go - producing parsers that are easier to understand and maintain (and are often
faster!).</p>
<p>It all ties in to the <a href="https://eli.thegreenplace.net/2017/benefits-of-dependencies-in-software-projects-as-a-function-of-effort/" target="_blank" rel="noopener noreferrer">benefits of dependencies in software projects as a
function of effort</a>.
Using parser generators is a heavy <em>conceptual</em> dependency: it's really nice
when you have to churn out many parsers for small languages. But when you have
to maintain a single, very complex parser, as part of a large project - the
benefits quickly dissipate and you're left with a substantial dependency that
you constantly grapple with.</p>
</div>
<div>
<h3>The other issue with dependencies</h3>
<p>And then there are the usual problems with dependencies; dependencies get
abandoned, and they may also develop security issues. Sometimes, both of these
become true.</p>
<p>Many years ago, pycparser forked and started vendoring its own version of PLY.
This was part of transitioning pycparser to a dual Python 2/3 code base when PLY
was slower to adapt. I believe this was the right decision, since PLY "just
worked" and I didn't have to deal with active (and very tedious in the Python
ecosystem, where packaging tools are replaced faster than dirty socks)
dependency management.</p>
<p>A couple of weeks ago <a href="https://github.com/eliben/pycparser/issues/588" target="_blank" rel="noopener noreferrer">this issue</a>
was opened for pycparser. It turns out the some old PLY code triggers security
checks used by some Linux distributions; while this code was fixed in a later
commit of PLY, PLY itself was apparently abandoned and archived in late 2025.
And guess what? That happened in the middle of a large rewrite of the package,
so re-vendoring the pre-archiving commit seemed like a risky proposition.</p>
<p>On the issue it was suggested that "hopefully the dependent packages move on to
a non-abandoned parser or implement their own"; I originally laughed this idea
off, but then it got me thinking... which is what this post is all about.</p>
</div>
<div>
<h3>Growing complexity of parsing a messy language</h3>
<p>The original K&amp;R2 grammar for C99 had - famously - a single shift-reduce
conflict having to do with dangling elses belonging to the most recent
if statement. And indeed, other than the famous <a href="https://en.wikipedia.org/wiki/Lexer_hack" target="_blank" rel="noopener noreferrer">lexer hack</a>
used to deal with <a href="https://eli.thegreenplace.net/2011/05/02/the-context-sensitivity-of-cs-grammar-revisited" target="_blank" rel="noopener noreferrer">C's type name / ID ambiguity</a>,
pycparser only had this single shift-reduce conflict.</p>
<p>But things got more complicated. Over the years, features were added that
weren't strictly in the standard but were supported by all the industrial
compilers. The more advanced C11 and C23 standards weren't beholden to the
promises of conflict-free YACC parsing (since almost no industrial-strength
compilers use YACC at this point), so all caution went out of the window.</p>
<p>The latest (PLY-based) release of pycparser has many reduce-reduce conflicts
<a href="#footnote-2" target="_blank" rel="noopener noreferrer">[2]</a>; these are a severe maintenance hazard because it means the parsing rules
essentially have to be tie-broken by order of appearance in the code. This is
very brittle; pycparser has only managed to maintain its stability and quality
through its comprehensive test suite. Over time, it became harder and harder to
extend, because YACC parsing rules have all kinds of spooky-action-at-a-distance
effects. The straw that broke the camel's back was <a href="https://github.com/eliben/pycparser/pull/590" target="_blank" rel="noopener noreferrer">this PR</a> which again proposed to
increase the number of reduce-reduce conflicts <a href="#footnote-3" target="_blank" rel="noopener noreferrer">[3]</a>.</p>
<p>This - again - prompted me to think "what if I just dump YACC and switch to
a hand-written recursive descent parser", and here we are.</p>
</div>
</div>
<div>
<h2>The mental roadblock</h2>
<p>None of the challenges described above are new; I've been pondering them for
many years now, and yet biting the bullet and rewriting the parser didn't feel
like something I'd like to get into. By my private estimates it'd take at least
a week of deep heads-down work to port the gritty 2000 lines of YACC grammar
rules to a recursive descent parser <a href="#footnote-4" target="_blank" rel="noopener noreferrer">[4]</a>. Moreover, it wouldn't be a
particularly <em>fun</em> project either - I didn't feel like I'd learn much new and
my interests have shifted away from this project. In short, the <a href="https://en.wikipedia.org/wiki/Potential_well" target="_blank" rel="noopener noreferrer">Potential well</a> was just too deep.</p>
</div>
<div>
<h2>Why would this even work? Tests</h2>
<p>I've definitely noticed the improvement in capabilities of LLM coding
agents in the past few months, and many reputable people online rave about using
them for increasingly larger projects. That said, would an LLM agent really be
able to accomplish such a complex project on its own? This isn't just a toy,
it's thousands of lines of dense parsing code.</p>
<p>What gave me hope is the concept of <a href="https://simonwillison.net/2025/Dec/31/the-year-in-llms/#the-year-of-conformance-suites" target="_blank" rel="noopener noreferrer">conformance suites mentioned by
Simon Willison</a>.
Agents seem to do well when there's a very clear and rigid
goal function - such as a large, high-coverage conformance test suite.</p>
<p>And pycparser has an <a href="https://github.com/eliben/pycparser/blob/main/tests/test_c_parser.py" target="_blank" rel="noopener noreferrer">very extensive one</a>.
Over 2500 lines of test code parsing various C snippets to ASTs with expected
results, grown over a decade and a half of real issues and bugs reported by
users.</p>
<p>I figured the LLM can either succeed or fail and throw its hands up in despair,
but it's quite unlikely to produce a <em>wrong</em> port that would still pass all
the tests. So I set it to run.</p>
</div>
<div>
<h2>The initial port</h2>
<p>I fired up Codex in pycparser's repository, and wrote this prompt just to
make sure it understands me and can run the tests:</p>
<div><pre><span></span>This repository implements a Python parser producing an AST. It has a very
extensive test suite; can you first verify you successfully run all the tests?
(with python3 -m unittest discover, from the root dir)
</pre></div>
<p>Codex figured it out (I gave it the exact command, after all!); my next
prompt was the real thing <a href="#footnote-5" target="_blank" rel="noopener noreferrer">[5]</a>:</p>
<div><pre><span></span>pycparser uses the PLY library for its lexer and parser, and its own AST
package for the ASTs created by the parser. I want to explore replacing the
Parser component (leaving the Lexer alone for now) with a hand written
recursive descent parser that will pass all the same tests. Can you try that?
</pre></div>
<p>Here Codex went to work and churned <em>for over an hour</em>. Having never
observed an agent work for nearly this long, I kind of assumed it went off
the rails and will fail sooner or later. So I was rather surprised and skeptical
when it eventually came back with:</p>
<div><pre><span></span>Replaced the PLY parse path with a handwritten recursive‑descent parser while
keeping the existing lexer and AST helpers intact; CParser now points to the
new RD implementation, with the old PLY version preserved as PLYCParser in
pycparser/c_parser.py. The RD parser includes a token stream, declarator/type
parsing, expression precedence handling, pragmas, and statement parsing to
match the previous AST output and coordinate behavior.
</pre></div>
<p>It took me a while to poke around the code and run it until I was convinced - it
had actually done it! It wrote a new recursive descent parser with only
ancillary dependencies on PLY, and that parser passed the test suite. After a
few more prompts, we've removed the ancillary dependencies and made the
structure clearer. I hadn't looked too deeply into code quality at this point,
but at least on the functional level - it succeeded. This was very impressive!</p>
</div>
<div>
<h2>A quick note on reviews and branches</h2>
<p>A change like the one described above is impossible to code-review as one PR in
any meaningful way; so I used a different strategy. Before embarking on this
path, I created a new branch and once Codex finished the initial rewrite, I
committed this change, knowing that I will review it in detail, piece-by-piece
later on.</p>
<p>Even though coding agents have their own notion of history and can "revert"
certain changes, I felt much safer relying on Git. In the worst case if all of
this goes south, I can nuke the branch and it's as if nothing ever happened.
I was determined to only merge this branch onto main once I was fully
satisfied with the code. In what follows, I had to git reset several times
when I didn't like the direction in which Codex was going. In hindsight, doing
this work in a branch was absolutely the right choice.</p>
</div>
<div>
<h2>The long tail of goofs</h2>
<p>Once I've sufficiently convinced myself that the new parser is actually working,
I used Codex to similarly rewrite the lexer and get rid of the PLY dependency
entirely, deleting it from the repository. Then, I started looking more deeply
into code quality - reading the code created by Codex and trying to wrap my head
around it.</p>
<p>And - oh my - this was quite the journey. Much has been written about the code
produced by agents, and much of it seems to be true. Maybe it's a setting I'm
missing (I'm not using my own custom AGENTS.md yet, for instance), but
Codex seems to be that eager programmer that wants to get from A to B whatever
the cost. Readability, minimalism and code clarity are very much secondary
goals.</p>
<p>Using <span>raise...except</span> for control flow? Yep. Abusing Python's weak typing
(like having None, false and other values all mean different things
for a given variable)? For sure. Spreading the logic of a complex function
all over the place instead of putting all the key parts in a single switch
statement? You bet.</p>
<p>Moreover, the agent is hilariously <em>lazy</em>. More than once I had to convince it
to do something it initially said is impossible, and even insisted again in
follow-up messages. The anthropomorphization here is mildly concerning, to be
honest. I could never imagine I would be writing something like the following to
a computer, and yet - here we are: "Remember how we moved X to Y before? You
can do it again for Z, definitely. Just try".</p>
<p>My process was to see how I can instruct Codex to fix things, and intervene
myself (by rewriting code) as little as possible. I've <em>mostly</em> succeeded in
this, and did maybe 20% of the work myself.</p>
<p>My branch grew <em>dozens</em> of commits, falling into roughly these categories:</p>
<ol>
<li>The code in X is too complex; why can't we do Y instead?</li>
<li>The use of X is needlessly convoluted; change Y to Z, and T to V in all
instances.</li>
<li>The code in X is unclear; please add a detailed comment - with examples - to
explain what it does.</li>
</ol>
<p>Interestingly, after doing (3), the agent was often more effective in giving
the code a "fresh look" and succeeding in either (1) or (2).</p>
</div>
<div>
<h2>The end result</h2>
<p>Eventually, after many hours spent in this process, I was reasonably pleased
with the code. It's far from perfect, of course, but taking the essential
complexities into account, it's something I could see myself maintaining (with
or without the help of an agent). I'm sure I'll find more ways to improve it
in the future, but I have a reasonable degree of confidence that this will be
doable.</p>
<p>It passes all the tests, so I've been able to release a new version (3.00)
without major issues so far. The only issue I've discovered is that some of
CFFI's tests are overly precise about the phrasing of errors reported by
pycparser; this was <a href="https://github.com/python-cffi/cffi/pull/224" target="_blank" rel="noopener noreferrer">an easy fix</a>.</p>
<p>The new parser is also faster, by about 30% based on my benchmarks! This is
typical of recursive descent when compared with YACC-generated parsers, in my
experience. After reviewing the initial rewrite of the lexer, I've spent a while
instructing Codex on how to make it faster, and it worked reasonably well.</p>
</div>
<div>
<h2>Followup - static typing</h2>
<p>While working on this, it became quite obvious that static typing would make the
process easier. LLM coding agents really benefit from closed loops with strict
guardrails (e.g. a test suite to pass), and type-annotations act as such.
For example, had pycparser already been type annotated, Codex would probably not
have overloaded values to multiple types (like None vs. False vs.
others).</p>
<p>In a followup, I asked Codex to type-annotate pycparser (running checks using
ty), and this was also a back-and-forth because the process exposed some
issues that needed to be refactored. Time will tell, but hopefully it will make
further changes in the project simpler for the agent.</p>
<p>Based on this experience, I'd bet that coding agents will be somewhat more
effective in strongly typed languages like Go, TypeScript and especially Rust.</p>
</div>
<div>
<h2>Conclusions</h2>
<p>Overall, this project has been a really good experience, and I'm impressed with
what modern LLM coding agents can do! While there's no reason to expect that
progress in this domain will stop, even if it does - these are already very
useful tools that can significantly improve programmer productivity.</p>
<p>Could I have done this myself, without an agent's help? Sure. But it would have
taken me <em>much</em> longer, assuming that I could even muster the will and
concentration to engage in this project. I estimate it would take me at least
a week of full-time work (so 30-40 hours) spread over who knows how long to
accomplish. With Codex, I put in an order of magnitude less work into this
(around 4-5 hours, I'd estimate) and I'm happy with the result.</p>
<p>It was also <em>fun</em>. At least in one sense, my professional life can be described
as the pursuit of focus, deep work and <em>flow</em>. It's not easy for me to get into
this state, but when I do I'm highly productive and find it very enjoyable.
Agents really help me here. When I know I need to write some code and it's
hard to get started, asking an agent to write a prototype is a great catalyst
for my motivation. Hence the meme at the beginning of the post.</p>
<div>
<h3>Does code quality even matter?</h3>
<p>One can't avoid a nagging question - does the quality of the code produced
by agents even matter? Clearly, the agents themselves can understand it (if not
today's agent, then at least next year's). Why worry about future
maintainability if the agent can maintain it? In other words, does it make sense
to just go full vibe-coding?</p>
<p>This is a fair question, and one I don't have an answer to. Right now, for
projects I maintain and <em>stand behind</em>, it seems obvious to me that the code
should be fully understandable and accepted by me, and the agent is just a tool
helping me get to that state more efficiently. It's hard to say what the future
holds here; it's going to interesting, for sure.</p>
<hr />
<table>
<colgroup><col></col><col></col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-1" target="_blank" rel="noopener noreferrer">[1]</a></td><td>pycparser has a fair number of <a href="https://deps.dev/pypi/pycparser/3.0.0/dependents" target="_blank" rel="noopener noreferrer">direct dependents</a>,
but the majority of downloads comes through <a href="https://github.com/python-cffi/cffi" target="_blank" rel="noopener noreferrer">CFFI</a>,
which itself is a major building block for much of the Python ecosystem.</td></tr>
</tbody>
</table>
<table>
<colgroup><col></col><col></col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-2" target="_blank" rel="noopener noreferrer">[2]</a></td><td>The table-building report says 177, but that's certainly an
over-dramatization because it's common for a single conflict to
manifest in several ways.</td></tr>
</tbody>
</table>
<table>
<colgroup><col></col><col></col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-3" target="_blank" rel="noopener noreferrer">[3]</a></td><td>It didn't help the PR's case that it was almost certainly vibe coded.</td></tr>
</tbody>
</table>
<table>
<colgroup><col></col><col></col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-4" target="_blank" rel="noopener noreferrer">[4]</a></td><td><p>There was also the lexer to consider, but this seemed like a much
simpler job. My impression is that in the early days of computing,
lex gained prominence because of strong regexp support which wasn't
very common yet. These days, with excellent regexp libraries
existing for pretty much every language, the added value of lex over
a <a href="https://eli.thegreenplace.net/2013/06/25/regex-based-lexical-analysis-in-python-and-javascript" target="_blank" rel="noopener noreferrer">custom regexp-based lexer</a>
isn't very high.</p>
<p>That said, it wouldn't make much sense to embark on a journey to rewrite
<em>just</em> the lexer; the dependency on PLY would still remain, and besides,
PLY's lexer and parser are designed to work well together. So it wouldn't
help me much without tackling the parser beast.</p>
</td></tr>
</tbody>
</table>
<table>
<colgroup><col></col><col></col></colgroup>
<tbody>
<tr><td><a href="#footnote-reference-5" target="_blank" rel="noopener noreferrer">[5]</a></td><td>I've decided to ask it to the port the parser first, leaving the lexer
alone. This was to split the work into reasonable chunks. Besides, I
figured that the parser is the hard job anyway - if it succeeds in that,
the lexer should be easy. That assumption turned out to be correct.</td></tr>
</tbody>
</table>
</div>
</div>
</div> <footer class="article-footer" data-astro-cid-wrgicudb> <div class="action-row" data-astro-cid-wrgicudb> <a href="https://eli.thegreenplace.net/2026/rewriting-pycparser-with-the-help-of-an-llm/" target="_blank" rel="noopener noreferrer" class="read-original-btn" data-astro-cid-wrgicudb>
阅读原文 ↗
</a> </div> <div class="back-to-list" data-astro-cid-wrgicudb> <a href="/reading-list" class="back-link" data-astro-cid-wrgicudb>← 返回订阅列表</a> </div> </footer> </article> </div>  </main> <footer class="site-footer" aria-label="Site footer" data-astro-cid-sz7xmlte> <div class="footer-content" data-astro-cid-sz7xmlte> <p class="footer-text" data-astro-cid-sz7xmlte>
&copy; 2026 AstroBlog
</p> <p class="footer-text" data-astro-cid-sz7xmlte>
Built with  <a href="https://astro.build/" target="_blank" rel="noopener noreferrer" class="footer-link" data-astro-cid-sz7xmlte>
Astro
</a> </p> </div> </footer>  </body></html> 