<!DOCTYPE html><html lang="zh-CN" data-astro-cid-sckkx6r4> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.16.1"><meta name="description" content="links on AI hardware, diffusion models, optogenetics, brain scanning."><link rel="canonical" href="https://blog.yuyins.com/reading-list/may-2021-gwernnet-newsletter-ycqgjd/"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://blog.yuyins.com/reading-list/may-2021-gwernnet-newsletter-ycqgjd/"><meta property="og:title" content="May 2021 Gwern.net Newsletter"><meta property="og:description" content="links on AI hardware, diffusion models, optogenetics, brain scanning."><meta property="og:image" content="https://blog.yuyins.com/favicon.svg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://blog.yuyins.com/reading-list/may-2021-gwernnet-newsletter-ycqgjd/"><meta property="twitter:title" content="May 2021 Gwern.net Newsletter"><meta property="twitter:description" content="links on AI hardware, diffusion models, optogenetics, brain scanning."><meta property="twitter:image" content="https://blog.yuyins.com/favicon.svg"><title>May 2021 Gwern.net Newsletter</title><!-- Theme and color scheme script (runs before page loads to prevent flash) --><script>
			// 初始化配色方案 - 默认使用 stone-amber
			const colorScheme = localStorage.getItem('colorScheme') || 'stone-amber';
			document.documentElement.setAttribute('data-color', colorScheme);

			// 强制使用浅色主题
			document.documentElement.setAttribute('data-theme', 'light');
		</script><link rel="stylesheet" href="/_astro/_slug_.C-G01a-E.css">
<style>.blog-post-container[data-astro-cid-wrgicudb]{width:100%;margin:0 auto;padding:2rem 0}.blog-post[data-astro-cid-wrgicudb]{width:100%;min-width:0;max-width:42rem;margin:0 auto}.article-header[data-astro-cid-wrgicudb]{margin-bottom:2rem;padding-bottom:1rem;border-bottom:1px solid var(--border)}.article-header[data-astro-cid-wrgicudb] h1[data-astro-cid-wrgicudb]{font-size:2rem;line-height:1.3;margin-bottom:1rem;font-weight:700;color:var(--foreground);word-break:break-word}.article-meta[data-astro-cid-wrgicudb]{display:flex;align-items:center;gap:.5rem;font-size:.875rem;color:var(--muted-foreground)}.source-tag[data-astro-cid-wrgicudb]{background-color:var(--muted);color:var(--foreground);padding:.125rem .5rem;border-radius:9999px;font-weight:500;font-size:.75rem;text-decoration:none;transition:opacity .2s}.source-tag[data-astro-cid-wrgicudb]:hover{opacity:.8}.separator[data-astro-cid-wrgicudb]{color:var(--border)}.article-content[data-astro-cid-wrgicudb]{line-height:1.8;margin-bottom:3rem;font-size:1.0625rem;color:var(--foreground)}.article-content[data-astro-cid-wrgicudb] h2{margin-top:2rem;margin-bottom:1rem;font-size:1.5rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] h3{margin-top:1.5rem;margin-bottom:.75rem;font-size:1.25rem;font-weight:600}.article-content[data-astro-cid-wrgicudb] p{margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] a{color:var(--accent);text-decoration:underline;text-underline-offset:2px}.article-content[data-astro-cid-wrgicudb] img{max-width:100%;height:auto;border-radius:.5rem;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] blockquote{border-left:4px solid var(--border);padding-left:1rem;margin:1.5rem 0;color:var(--muted-foreground);font-style:italic}.article-content[data-astro-cid-wrgicudb] pre{background:var(--muted);padding:1rem;border-radius:.5rem;overflow-x:auto;font-family:monospace;margin:1.5rem 0}.article-content[data-astro-cid-wrgicudb] ul,.article-content[data-astro-cid-wrgicudb] ol{padding-left:1.5rem;margin-bottom:1.25rem}.article-content[data-astro-cid-wrgicudb] li{margin-bottom:.5rem}.article-footer[data-astro-cid-wrgicudb]{padding-top:2rem;border-top:1px solid var(--border);display:flex;flex-direction:column;gap:1.5rem;align-items:center}.action-row[data-astro-cid-wrgicudb]{display:flex;justify-content:center}.read-original-btn[data-astro-cid-wrgicudb]{display:inline-flex;align-items:center;gap:.5rem;padding:.75rem 1.5rem;background-color:var(--foreground);color:var(--background);border-radius:.5rem;font-weight:500;text-decoration:none;transition:opacity .2s}.read-original-btn[data-astro-cid-wrgicudb]:hover{opacity:.9}.back-to-list[data-astro-cid-wrgicudb]{text-align:center}.back-link[data-astro-cid-wrgicudb]{color:var(--muted-foreground);text-decoration:none;font-size:.875rem;transition:color .2s}.back-link[data-astro-cid-wrgicudb]:hover{color:var(--foreground)}
</style></head> <body data-astro-cid-sckkx6r4> <a id="skip-to-content" href="#main-content" class="sr-only focus:not-sr-only focus:absolute focus:top-4 focus:left-4 focus:z-50 focus:px-4 focus:py-2 focus:bg-accent focus:text-background" data-astro-cid-sckkx6r4>Skip to content</a> <header class="header" data-astro-cid-3ef6ksr2> <nav class="header-nav" aria-label="Main navigation" data-astro-cid-3ef6ksr2> <a href="/" class="header-logo" data-astro-cid-3ef6ksr2>
AstroBlog
</a> <div class="header-links" data-astro-cid-3ef6ksr2> <ul class="nav-list" data-astro-cid-3ef6ksr2> <li data-astro-cid-3ef6ksr2> <a href="/" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 文章 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/category" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 分类 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/reading-list" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 订阅 </a> </li><li data-astro-cid-3ef6ksr2> <a href="/about" class="nav-link" data-astro-prefetch="true" data-astro-cid-3ef6ksr2> 关于 </a> </li> </ul> <div class="header-actions" data-astro-cid-3ef6ksr2> <div id="search" data-astro-cid-otpdt6jm> <button id="search-button" class="search-toggle" aria-label="打开搜索" title="搜索 (⌘K)" data-astro-cid-otpdt6jm> <svg class="search-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <circle cx="11" cy="11" r="7" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></circle> <path d="M20 20L16.5 16.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" data-astro-cid-otpdt6jm></path> </svg> </button> <dialog id="search-dialog" class="search-modal" data-astro-cid-otpdt6jm> <div class="modal-content" data-astro-cid-otpdt6jm> <div class="modal-header" data-astro-cid-otpdt6jm> <h2 class="modal-title" data-astro-cid-otpdt6jm>搜索文章</h2> <button id="close-search" class="close-button" aria-label="关闭搜索" data-astro-cid-otpdt6jm> <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-otpdt6jm> <path d="M18 6L6 18M6 6l12 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-otpdt6jm></path> </svg> </button> </div> <div id="pagefind-ui" data-astro-cid-otpdt6jm></div> </div> </dialog> </div> <script type="module">let d=!1;const c="pagefind-loaded";async function l(t=0){if(sessionStorage.getItem(c)==="true")return g(),!0;const r=document.getElementById("pagefind-ui");if(!r)return!1;r.innerHTML='<div style="padding: 2rem; text-align: center; color: var(--muted-foreground);">加载中...</div>';try{return await new Promise((o,s)=>{const a=document.createElement("script");a.src="/pagefind/pagefind-ui.js",a.onload=o,a.onerror=s,document.head.appendChild(a)}),g(),sessionStorage.setItem(c,"true"),!0}catch(i){return console.error("Failed to load search:",i),t<2?(console.log(`Retrying search load... (${t+1}/2)`),await new Promise(o=>setTimeout(o,1e3)),l(t+1)):(r&&(r.innerHTML=`
          <div style="padding: 2rem; text-align: center;">
            <p style="color: var(--muted-foreground); margin-bottom: 1rem;">搜索功能加载失败</p>
            <button id="retry-search" style="padding: 0.5rem 1rem; background: var(--accent); color: var(--accent-foreground); border: none; border-radius: 0.375rem; cursor: pointer;">
              重试
            </button>
          </div>
        `,document.getElementById("retry-search")?.addEventListener("click",()=>{sessionStorage.removeItem(c),l(0)})),!1)}}function g(){typeof PagefindUI<"u"&&(new PagefindUI({element:"#pagefind-ui",showSubResults:!0,showImages:!1,excerptLength:15,translations:{placeholder:"搜索文章...",clear_search:"清除",load_more:"加载更多",search_label:"搜索此站点",filters_label:"筛选",zero_results:"未找到结果 [SEARCH_TERM]",many_results:"找到 [COUNT] 个结果 [SEARCH_TERM]",one_result:"找到 [COUNT] 个结果 [SEARCH_TERM]",alt_search:"未找到 [SEARCH_TERM] 的结果。显示 [DIFFERENT_TERM] 的结果",search_suggestion:"未找到 [SEARCH_TERM] 的结果。尝试以下搜索：",searching:"搜索中 [SEARCH_TERM]..."}}),setTimeout(()=>{const t=document.querySelector(".pagefind-ui__search-input");t instanceof HTMLElement&&t.focus()},100))}function u(){if(d)return;d=!0;const t=document.getElementById("search-button"),n=document.getElementById("search-dialog"),r=document.getElementById("close-search");if(!t||!n||!r)return;let i=sessionStorage.getItem(c)==="true";const o=async()=>{n.showModal(),document.body.style.overflow="hidden",i?setTimeout(()=>{const e=document.querySelector(".pagefind-ui__search-input");e instanceof HTMLElement&&e.focus()},100):await l()&&(i=!0)},s=()=>{n.close(),document.body.style.overflow=""},a=e=>{e.target===n&&s()},m=e=>{e.key==="Escape"&&n.open&&s()},f=e=>{(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),n.open?s():o())};t.addEventListener("click",o),r.addEventListener("click",s),n.addEventListener("click",a),document.addEventListener("keydown",m),document.addEventListener("keydown",f),document.addEventListener("astro:before-swap",()=>{t.removeEventListener("click",o),r.removeEventListener("click",s),n.removeEventListener("click",a),document.removeEventListener("keydown",m),document.removeEventListener("keydown",f),d=!1},{once:!0})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",u):u();document.addEventListener("astro:page-load",u);</script> <link href="/pagefind/pagefind-ui.css" rel="stylesheet">  </div> </div> </nav> </header>  <main id="main-content" data-pagefind-body class="main-content main-content--wide" data-astro-cid-sckkx6r4>  <div class="blog-post-container" data-astro-cid-wrgicudb> <article class="blog-post" data-astro-cid-wrgicudb> <header class="article-header" data-astro-cid-wrgicudb> <h1 data-astro-cid-wrgicudb>May 2021 Gwern.net Newsletter</h1> <div class="article-meta" data-astro-cid-wrgicudb> <a href="https://gwern.net" target="_blank" rel="noopener noreferrer" class="source-tag" data-astro-cid-wrgicudb>gwern.net</a> <span class="separator" data-astro-cid-wrgicudb>·</span> <time data-astro-cid-wrgicudb>2021年6月11日</time> </div> </header> <!-- Render HTML content from RSS feed --> <div class="article-content app-prose" data-astro-cid-wrgicudb><p>May 2021&#8217;s <a href="https://www.gwern.net/newsletter/2021/05">Gwern.net</a> <a href="https://gwern.substack.com">newsletter</a> is now out; previous, <a href="https://www.gwern.net/newsletter/2021/04">April 2021</a> (<a href="https://www.gwern.net/tags/newsletter">archives</a>). This is a collation of links and summary of major changes, overlapping with my <a href="https://www.gwern.net/Changelog">Changelog</a>; brought to you by my donors on <a href="https://www.patreon.com/gwern">Patreon</a>.</p><p>Note: I will be in Denver 12&#8211;13 June 2021 for a conference.</p><h1>1 Writings</h1><ul><li><p><strong>Proposal</strong>: <a href="https://www.gwern.net/CYOA">&#8220;Choose Your Own Adventure AI Dungeon&#8221;</a>; <a href="https://www.gwern.net/GPT-2-preference-learning#decision-transformers-preference-learning-as-simple-as-possible">&#8220;Decision Transformers: Preference Learning As Simple As Possible&#8221;</a></p></li></ul><h1>2 Links</h1><h2>2.1 AI</h2><p><a href="https://old.reddit.com/r/mlscaling/">Matters Of Scale</a>:</p><ul><li><p><strong>Hardware</strong>:</p><ul><li><p><a href="https://arxiv.org/abs/2104.06272#deepmind">&#8220;Podracer architectures for scalable Reinforcement Learning&#8221;</a>, Hessel et al 2021 (highly-efficient TPU pod use: eg solving Pong in &lt;1min at 43 million FPS on a TPUv3-2048); <a href="https://venturebeat.com/2021/05/18/google-details-new-ai-accelerator-chips/">&#8220;Google details new TPUv4 AI accelerator chips&#8221;</a> (2.7&#215; TPUv3 chips; up to TPUv4-4096 pods, yielding &gt;1 ExaFLOPS; public access later in 2021)x</p></li><li><p><a href="https://arxiv.org/abs/2104.07857#microsoft">&#8220;ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning&#8221;</a>, Rajbhandari et al 2021 (~1 trillion parameters per 16 GPUs/DGX-2-node, scaling to &gt;512 GPUs ~40% efficiency)</p></li><li><p><a href="https://arxiv.org/abs/2105.04663#google">&#8220;GSPMD: General and Scalable Parallelization for ML Computation Graphs&#8221;</a>, Xu et al 2021 (Google upgrade of <a href="https://arxiv.org/abs/1811.06965#google" title="'GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism', Huang et al 2018">GPipe</a>/<a href="https://arxiv.org/abs/2006.16668#google" title="'GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding', Lepikhin et al 2020">GShard</a> arch to match <a href="https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/" title="DeepSpeed: Extreme-scale model training for everyone">MS DeepSpeed</a>: &#8220;&#8230;50%&#8211;62% compute utilization on 128&#8211;2048 Cloud TPUv3 cores for models with up to one trillion parameters&#8221;)</p></li><li><p><a href="https://arxiv.org/abs/2104.05158#facebook">&#8220;DLRM: High-performance, Distributed Training of Large-scale Deep Learning Recommendation Models&#8221;</a>,  Mudigere et al 2021 (ZionEX software/hardware platform for training  extremely large embeddings&#8212;while embeddings aren&#8217;t &#8216;real&#8217; parameters  &amp; things like <a href="https://arxiv.org/abs/2004.08366#google" title="'DynamicEmbedding: Extending TensorFlow for Colossal-Scale Applications', Zeng et al 2020">DynamicEmbedding</a> will never learn tricks like GPT-3 no matter how big, they present similar challenges); <a href="https://arxiv.org/abs/2105.08820#facebook">&#8220;RecPipe: Co-designing Models and Hardware to Jointly Optimize Recommendation Quality and Performance&#8221;</a>, Gupta et al 2021</p></li></ul></li><li><p><a href="https://arxiv.org/abs/2105.12196#deepmind">&#8220;From Motor Control to Team Play in Simulated Humanoid Football&#8221;</a>,  Liu et al 2021 (curriculum training of a single NN from raw humanoid  control to coordinated team-wide soccer strategy; neat to compare with <a href="https://arxiv.org/abs/2009.01719#deepmind" title="Grounded Language Learning Fast and Slow">Hill et al 2020</a> in terms of agent abilities)</p></li><li><p><a href="https://arxiv.org/abs/2105.11084#facebook">&#8220;Wav2vec-U: Unsupervised Speech Recognition&#8221;</a>, Baevski et al 2021</p></li><li><p><a href="https://www.anthropic.com/news/announcement">&#8220;Anthropic&#8221; public-benefit-corp/startup launched</a> (founded by the Amodeis; $124M investment for scaling &#8220;reliable and steerable AI systems&#8221;); <a href="https://www.cooperativeai.com/foundation">&#8220;Cooperative AI Foundation&#8221; (CAIF)</a> launched</p></li><li><p><a href="https://arxiv.org/abs/2105.01601#google">&#8220;MLP-Mixer: An all-MLP Architecture for Vision&#8221;</a>, Tolstikhin et al 2021 (another <a href="https://www.gwern.net/notes/FC">FC paper</a> removing even more inductive biases&#8212;ponies are all you need: &#8220;Mixer <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">improves more rapidly with data</a>  than ResNets, or even ViT, and the gap between large scale Mixer and  ViT models shrinks until the performance is matched on the entire  dataset&#8230;&#8221; The Bitter Lesson truly is the single bitterest lesson in ML,  isn&#8217;t it? The more people tweet about how MLP-Mixer is overhyped because  is &#8722;X% worse than the ultra-hand-optimized baseline or requires Y&#215; more  FLOPS, the more they demonstrate <em>precisely why</em> this sort of  research is so important! And showing, incidentally, that Transformers  are still under-researched if such a fundamental fact could have been  missed for so long.)</p></li><li><p><a href="https://arxiv.org/abs/2104.08945#facebook">&#8220;Data-Efficient Language-Supervised Zero-Shot Learning with Self-Distillation&#8221;</a>, Cheng et al 2021 (<a href="https://openai.com/blog/clip/">CLIP</a>-like performance scaled down to <em>n</em> = 3m using <a href="https://arxiv.org/abs/1503.02531#google" title="'Distilling the knowledge in a neural network', Hinton et al 2015">soft labels</a> generated by a <a href="https://www.gwern.net/docs/ai/2018-sharma.pdf#google" title="Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning">Conceptual Captions</a>-pretrained model)</p></li><li><p><a href="https://arxiv.org/abs/2104.07636#google">&#8220;SR3: Image Super-Resolution via Iterative Refinement&#8221;</a>, Saharia et al 2021; <a href="https://arxiv.org/abs/2105.05233#openai">&#8220;Diffusion Models Beat GANs on Image Synthesis&#8221;</a>, Dhariwal &amp; Nichol 2021 (<a href="https://arxiv.org/abs/2006.11239" title="'Denoising Diffusion Probabilistic Models', Ho et al 2020">DDPM</a>^<a href="file:///tmp/burlbC6ws6.html#fn1">1</a>^ finally surpass <a href="https://arxiv.org/abs/1809.11096#deepmind" title="'BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis', Brock et al 2018">BigGAN-deep</a> on ImageNet 512px images at similar compute-cost, as <a href="https://arxiv.org/abs/2102.09672" title="'Improved Denoising Diffusion Probabilistic Models', Nichol &amp; Dhariwal 2021">expected from their</a><a href="https://www.gwern.net/notes/Scaling">good scaling</a>); <a href="https://cascaded-diffusion.github.io/">&#8220;Cascaded Diffusion Models for High Fidelity Image Generation&#8221;</a>, Ho et al 2021</p></li><li><p><a href="https://arxiv.org/abs/2009.01325#openai">&#8220;Learning to summarize from human feedback&#8221;</a>, Stiennon et al 2020</p></li><li><p><a href="https://www.gwern.net/docs/ai/2021-power.pdf#openai">&#8220;Grokking: Generalization Beyond Overfitting On Small Algorithmic Data Sets&#8221;</a>, Power et al 2021 (<a href="https://old.reddit.com/r/mlscaling/comments/n78584/grokking_generalization_beyond_overfitting_on/">discussion</a>;  new scaling effect, &#8216;grokking&#8217;: sudden perfect generalization emerging  many epochs after training-set overfitting on algorithmic tasks when  training in <a href="https://www.gwern.net/docs/ai/2021-power-poster.png#openai">flat shallow loss landscapes</a>); <a href="https://arxiv.org/abs/2106.05237#google">&#8220;Knowledge distillation: A good teacher is patient and consistent&#8221;</a>, Beyer et al 2021 (training much smaller models merely requires hundreds of thousands or millions of epochs)</p></li><li><p><a href="https://arxiv.org/abs/2104.14830#google">&#8220;Scaling End-to-End Models for Large-Scale Multilingual ASR&#8221;</a>, Li et al 2021</p></li><li><p><a href="https://arxiv.org/abs/2103.10948">&#8220;The Shape of Learning Curves: a Review&#8221;</a>, Viering &amp; Loog 2021</p></li><li><p><a href="https://www.sciencedirect.com/science/article/pii/S0004370221000862#deepmind">&#8220;Reward is enough&#8221;</a>,  Silver et al 2021 (a DRL manifesto: reward losses enough at scale of  compute/parameters/tasks to induce all important capabilities like  memory/exploration/generalization/imitation/reasoning)</p></li><li><p><strong>Scaling Down</strong>: <a href="https://github.com/nshepperd/lazy"><code>lazy</code>: a tool for running processes in idle time</a> (how to train on a GPU without destroying your GUI&#8217;s usability! <code>lazy</code>  pauses runs briefly while you interact with your desktop, letting you  do months-long runs without going crazy or resorting to Colab etc. This  enables hobbyists to go after previously-infeasible model sizes);  EleutherAI releases <a href="https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/">a 6b-parameter GPT-3 model, GPT-J</a> (are you still using GPT-2/GPT-Neo? upgrade!); <a href="https://arxiv.org/abs/2105.12723">&#8220;Aggregating Nested Transformers&#8221;</a>, Zhang et al 2021/<a href="https://arxiv.org/abs/2105.14217">&#8220;Less is More: Pay Less Attention in Vision Transformers&#8221;</a>, Pan et al 2021</p></li></ul><ul><li><p><a href="https://arxiv.org/abs/2105.13626#google">&#8220;ByT5: Towards a token-free future with pre-trained byte-to-byte models&#8221;</a>, Xue et al 2021 (character models&#8212;not just feasible but desirable; we&#8217;ll get our rhyming &amp; pun-making language models yet!)</p></li><li><p><a href="https://www.gwern.net/docs/ai/2008-golle.pdf">&#8220;Machine Learning Attacks Against the Asirra CAPTCHA&#8221;</a>,  Golle 2008 (a look back on a decade of CV progress: months of work for  80% cat vs dog with SVM ensembles in 2008; 5min in Fast.ai for 99%  accuracy in 2018; for even more perspective, <a href="https://www.gwern.net/docs/ai/2012-ciresan.pdf" title="Deep big multilayer perceptrons for digit recognition">Cire&#351;an 2012</a>)</p></li></ul><h2>2.2 Genetics</h2><p>Everything Is Heritable:</p><ul><li><p><a href="https://www.gwern.net/docs/genetics/heritable/2021-levey.pdf">&#8220;Bi-ancestral  depression GWAS in the Million Veteran Program and meta-analysis in  &gt;1.2 million individuals highlight new therapeutic directions&#8221;</a>, Levey et al 2021</p></li><li><p><a href="https://www.biorxiv.org/content/10.1101/2021.05.26.445798v1">&#8220;The complete sequence of a human genome&#8221;</a>, Nurk et al 2021 (<a href="https://www.nature.com/articles/d41586-021-01506-w" title="A complete human genome sequence is close: how scientists filled in the gaps; researchers added 200 million DNA base pairs and 115 protein-coding genes &#8212; but they&#8217;ve yet to entirely sequence the Y chromosome">media</a>)</p></li><li><p><a href="https://www.gwern.net/docs/iq/2021-vonstumm.pdf">&#8220;Using DNA to predict intelligence&#8221;</a>, von Stumm &amp; Plomin 2021 (review)</p></li><li><p><a href="https://www.biorxiv.org/content/10.1101/848366v2.full">&#8220;Long  read sequencing of 3,622 Icelanders provides insight into the role of  structural variants in human diseases and other traits&#8221;</a>, Beyter et al 2021</p></li><li><p><a href="https://www.gwern.net/docs/genetics/heritable/2021-owen.pdf">&#8220;Rapid Sequencing&#8211;Based Diagnosis of Thiamine Metabolism Dysfunction Syndrome&#8221;</a> (sequence everyone!)</p></li></ul><p>Engineering:</p><ul><li><p><a href="https://www.gwern.net/docs/genetics/editing/2021-robertson.pdf">&#8220;Sense codon reassignment enables viral resistance and encoded polymer synthesis&#8221;</a>,  Robertson et al 2021 (&#8220;ultra-safe cells&#8221;: synthesizing an entire E.  coli genome with swapped codons for complete viral immunity)</p></li><li><p><a href="https://www.gwern.net/docs/genetics/editing/2021-musunuru.pdf">&#8220;In vivo CRISPR base editing of </a><em><a href="https://www.gwern.net/docs/genetics/editing/2021-musunuru.pdf">PCSK9</a></em><a href="https://www.gwern.net/docs/genetics/editing/2021-musunuru.pdf"> durably lowers cholesterol in primates&#8221;</a>, Musunuru et al 2021</p></li><li><p><strong><a href="https://en.wikipedia.org/wiki/Optogenetics">Optogenetics</a></strong>: <a href="https://www.gwern.net/docs/genetics/editing/2021-sahel.pdf">&#8220;Partial recovery of visual function in a blind patient after optogenetic therapy&#8221;</a>, Sahel et al 2021 (<a href="https://www.statnews.com/2021/05/24/scientists-use-optogenetics-for-first-time-to-help-blind-patient-see/" title="With engineered proteins, scientists use optogenetics for the first time to help a blind patient see again">media</a>); <a href="https://www.gwern.net/docs/biology/2021-yang.pdf">&#8220;Wireless multilateral devices for optogenetic studies of individual and social behaviors&#8221;</a>, Yang et al 2021 (<a href="https://www.nytimes.com/2021/05/25/science/optogenetics-brain-social-behavior.html" title="Scientists Drove Mice to Bond by Zapping Their Brains With Light: The study, a tour de force in bioengineering, comes after 2 decades of research on brain-to-brain synchrony in people">media</a>)</p></li><li><p><a href="https://www.pnas.org/content/118/18/e2018181118">&#8220;Retron Library Recombineering (RLR): High-throughput functional variant screens via in vivo production of single-stranded DNA&#8221;</a>, Schubert et al 2021</p></li><li><p><a href="https://www.nature.com/articles/d41586-021-01186-6">&#8220;First genetically modified Oxitec mosquitoes released in the United States&#8221;</a></p></li><li><p><a href="https://www.biorxiv.org/content/10.1101/2021.05.28.446207v1">&#8220;Genomic characterization of world&#8217;s longest selection experiment in mouse reveals the complexity of polygenic traits&#8221;</a>, Palma-Vera et al 2021</p></li><li><p><a href="https://www.sciencedirect.com/science/article/pii/S0734975021000628">&#8220;Surrogate broodstock to enhance biotechnology research and applications in aquaculture&#8221;</a>, Jin et al 2021</p></li><li><p><a href="https://www.biorxiv.org/content/10.1101/2020.11.05.370478v3">&#8220;Utility of polygenic embryo screening for disease depends on the selection strategy&#8221;</a>, Lencz et al 2021</p></li><li><p><a href="https://www.nature.com/articles/d41586-021-01423-y">&#8220;Limit  on lab-grown human embryos dropped by stem-cell body: The International  Society for Stem Cell Research relaxed the famous 14-day rule on  culturing human embryos in its latest research guidelines&#8221;</a></p></li><li><p><a href="https://www.nytimes.com/2007/08/28/science/28crop.html">&#8220;Useful Mutants, Bred With Radiation&#8221;</a> (on <a href="https://en.wikipedia.org/wiki/Atomic_gardening">atomic gardening</a>)</p></li></ul><h2>2.3 Statistics/Meta-Science</h2><ul><li><p><a href="https://blog.dshr.org/2021/03/correlated-failures.html">&#8220;Correlated Failures&#8221; in HDDs/SSDs</a></p></li><li><p><a href="https://www.gwern.net/docs/statistics/bias/1992-rogers.pdf">&#8220;How a Publicity Blitz Created The Myth of Subliminal Advertising&#8221;</a>, Rogers 1992 (the famous movie-theater/popcorn-sales experiment never happened)</p></li></ul><h2>2.4 Politics/Religion</h2><ul><li><p><a href="https://www.gwern.net/docs/sociology/2021-costello.pdf">&#8220;Clarifying the Structure and Nature of Left-Wing Authoritarianism (LWA)&#8221;</a>, Costello et al 2021</p></li><li><p><a href="https://fantasticanachronism.com/2021/04/28/book-review-the-decline-and-fall-of-the-roman-empire/">&#8220;Book Review: </a><em><a href="https://fantasticanachronism.com/2021/04/28/book-review-the-decline-and-fall-of-the-roman-empire/">The Decline and Fall of the Roman Empire</a></em><a href="https://fantasticanachronism.com/2021/04/28/book-review-the-decline-and-fall-of-the-roman-empire/">&#8221;</a> (<a href="https://fantasticanachronism.com/2021/05/03/highlights-from-the-decline-and-fall-of-the-roman-empire/">excerpts</a>)</p></li></ul><h2>2.5 Psychology/Biology</h2><ul><li><p><a href="https://www.biorxiv.org/content/10.1101/2021.05.29.446289v1">&#8220;A connectomic study of a petascale fragment of human cerebral cortex&#8221;</a>,  Shapson-Coe et al 2021 (&#8220;&#8230;This &#8220;digital tissue&#8221; is a ~660,000&#215; scale up  of an earlier saturated reconstruction from a small region of mouse  cortex, published in 2015 (<a href="https://www.sciencedirect.com/science/article/pii/S0092867415008247" title="Saturated Reconstruction of a Volume of Neocortex">Kasthuri et al 2015</a>).  Although this scaleup was difficult, it was not hundreds of thousands  of times more difficult and took about the same amount of time as the  previous data set (~4 years)&#8230;The rapid improvements over the past few  years&#8230;argues that analyzing volumes that are even 3 orders of magnitude  larger, such as an exascale whole mouse brain connectome, will likely be  in reach within a decade." See also <a href="https://xcorr.net/2021/04/27/accelerating-progress-in-brain-recording-tech/">&#8220;Accelerating progress in brain recording tech&#8221;</a>.)</p></li><li><p><a href="https://www.nature.com/articles/s41467-021-22199-9">&#8220;Neuroimaging evidence for a network sampling theory of individual differences in human intelligence test performance&#8221;</a>, Soreq et al 2021; <a href="https://elifesciences.org/articles/64058">&#8220;The neural basis of intelligence in fine-grained cortical topographies&#8221;</a>, Feilong et al 2021; <a href="https://link.springer.com/article/10.1007/s00429-020-02113-7">&#8220;Predicting intelligence from brain gray matter volume&#8221;</a>, Hilger et al 2020 (towards the mechanistic reification of <em>g</em>: per <a href="https://www.gwern.net/docs/iq/2007-jung.pdf" title="'The Parieto-Frontal Integration Theory (P-FIT) of intelligence: Converging neuroimaging evidence', Jung &amp; Haier 2007">P-FIT</a>,  it is global efficiency/total cognitive resources which can be spent on  learning &amp; orchestrating specialized capabilities); if we consider  recent human brain imaging studies, cross-species comparisons, and deep  learning as converging, I would offer as a speculation the following:</p><p>The Master Synthesis: intelligence  is execution of small simplicity-weighted programs, best discovered by  search over smooth loss landscapes like that of <a href="https://www.gwern.net/notes/Sparsity">highly-overparameterized</a> differentiable networks containing lottery-ticket subnetworks which are ensembled/averaged over, <a href="https://www.gwern.net/Backstop#deep-bayes">approaching Bayes-optimal</a>  reasoning in the limit (as nearest-neighbors-like high dimensional  interpolation / memorization gives way to algorithmic generalization /  interpolation on a more abstract level); this can be implemented by  large numbers of similar neurons trained using any of the many  approximations to backprop; human intelligence&#8217;s <em>g</em> is real but  is the overall &#8216;pool&#8217; of neural resources which derives from overall  body integrity because the number of neurons, their density, their  myelination, resistance to damage and infection etc, is causally  downstream of all body and developmental systems, creating a huge  mutational target; the brain regions specialize and differentiate, and  their orchestration (or lack thereof) contributes to observed  performance on tasks tapping into multiple specialized regions; as tasks  rely on fewer regions or approach intrinsic ceiling, <em>g</em> ceases to be observable and task-specific influences matter most.</p></li><li><p><a href="https://www.nature.com/articles/s41591-021-01336-3">&#8220;MDMA-assisted therapy for severe PTSD: a randomized, double-blind, placebo-controlled phase 3 study&#8221;</a>, Mitchell et al 2021 (<em>d</em> = 0.9 over therapy); <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7643046/">&#8220;Effects of Psilocybin-Assisted Therapy on Major Depressive Disorder&#8221;</a>, Davis et al 2021</p></li><li><p><a href="https://www.newyorker.com/magazine/2021/04/05/why-animals-dont-get-lost">&#8220;Why  Animals Don&#8217;t Get Lost: Birds do it. Bees do it. Learning about the  astounding navigational feats of wild creatures can teach us a lot about  where we&#8217;re going&#8221;</a> (on spectacular but still mysterious feats of <a href="https://en.wikipedia.org/wiki/Animal_navigation">animal navigation</a>)</p></li><li><p><a href="https://defector.com/in-the-future-of-collecting-is-anyone-having-fun/">&#8220;In The Future Of Collecting, Is Anyone Having Fun?&#8221;</a> (on <a href="https://en.wikipedia.org/wiki/Bobblehead">Bobblehead</a> collectors)</p></li><li><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8114859/">&#8220;Linking Brain Biology to Intellectual Endowment: A Review on the Associations of Human Intelligence With Neuroimaging Data&#8221;</a>, Dizaji et al 2021</p></li><li><p><a href="https://www.gwern.net/docs/economics/2012-oboyle.pdf">&#8220;The Best And The Rest: Revisiting The Norm Of Normality Of Individual Performance&#8221;</a>, O&#8217;Boyle &amp; Aguinis 2012 (performance is <a href="https://www.gwern.net/notes/Pipeline">log-normal</a>)</p></li><li><p><a href="https://www.biorxiv.org/content/10.1101/2020.11.21.392720v1">&#8220;A conserved strategy for inducing appendage regeneration&#8221;</a>, Abrams et al 2021 (slight regrowth of damaged mouse limbs by drinking sugar+amino-acid-supplemented water)</p></li><li><p><a href="https://astralcodexten.substack.com/p/know-your-amphetamines">&#8220;Know Your Amphetamines&#8221;</a>, Scott Alexander</p></li><li><p><a href="https://www.nature.com/articles/srep02617">&#8220;Feeling Small: Exploring the Tactile Perception Limits [of Humans]&#8221;</a>, Skedung et al 2013</p></li><li><p><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">&#8220;The Board Game of the Alpha Nerds: Before </a><em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">Risk</a></em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">, before </a><em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">Dungeons &amp; Dragons</a></em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">, before </a><em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">Magic: The Gathering</a></em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">, there was </a><em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">Diplomacy</a></em><a href="http://grantland.com/features/diplomacy-the-board-game-of-the-alpha-nerds/" title="One writer enters international competition to play the world-conquering game that redefines what it means to be a geek (and a person)">&#8221;</a> (<a href="https://en.wikipedia.org/wiki/Diplomacy_(game)">WP</a>;  &#8220;I still don&#8217;t know whom I should have trusted, if anyone. All I know  is that I felt stupid, stressed out, humiliated, and sad.&#8221;)</p></li></ul><h2>2.6 Technology</h2><ul><li><p><a href="https://rootsofprogress.org/nuclear-physics">&#8220;I walk the (beta-stability) line: How counting neutrons explains nuclear waste&#8221;</a></p></li><li><p><a href="https://alexdanco.com/2020/10/08/making-is-show-business-now/">&#8220;Making is Show Business now&#8221;</a>, Alex Danco</p></li><li><p><a href="https://www.thenewatlantis.com/publications/shop-class-as-soulcraft">&#8220;Shop Class as Soulcraft: The case for the manual trades&#8221;</a>, Crawford 2006</p></li><li><p><a href="https://www.kickstarter.com/projects/upperstory/spintronics-build-mechanical-circuits">&#8220;Spintronics: Build mechanical circuits&#8221;</a>, Kickstarter (followup to <a href="https://en.wikipedia.org/wiki/Turing_Tumble">Turing Tumble</a>)</p></li></ul><h2>2.7 Economics</h2><ul><li><p><a href="https://www.gwern.net/docs/sociology/2020-dellavigna.pdf">&#8220;RCTs to Scale: Comprehensive Evidence from 2 Nudge Units&#8221;</a>, DellaVigna &amp; Linos 2020 (nudge effects overestimated by 6.2&#215; due to publication bias)</p></li><li><p><a href="https://academic.oup.com/ije/advance-article/doi/10.1093/ije/dyab099/6288123">&#8220;No  causal associations between childhood family income and subsequent  psychiatric disorders, substance misuse and violent crime arrests: a  nationwide Finnish study of &gt;650,000 individuals and their siblings&#8221;</a>, Sariaslan et al 2021; <a href="https://academic.oup.com/ije/advance-article/doi/10.1093/ije/dyab066/6274255">&#8220;Parental income and mental disorders in children and adolescents: prospective register-based study&#8221;</a>, Kinge et al 2021</p></li><li><p><a href="https://mattlakeman.org/2021/06/01/everything-you-might-want-to-know-about-whaling/">&#8220;Everything You Might Want to Know about Whaling&#8221;</a>, Matt Lakeman</p></li><li><p><a href="https://www.gwern.net/notes/Nash">Exploding Nash Equilibrium For Trustless Trade</a></p></li></ul><h2>2.8 Fiction</h2><ul><li><p><a href="https://www.lightspeedmagazine.com/fiction/love-is-the-plan-the-plan-is-death/">&#8220;Love Is the Plan the Plan Is Death&#8221;</a>, <a href="https://en.wikipedia.org/wiki/James_Tiptree_Jr.">James Tiptree, Jr.</a> (<a href="https://en.wikipedia.org/wiki/Love_Is_the_Plan_the_Plan_Is_Death">WP</a>)</p></li></ul><h2>2.9 Miscellaneous</h2><ul><li><p><a href="https://www.newyorker.com/news/dispatch/the-strange-story-of-dagobert-the-ducktales-bandit">&#8220;The Strange Story of Dagobert, the </a><em><a href="https://www.newyorker.com/news/dispatch/the-strange-story-of-dagobert-the-ducktales-bandit">Duck Tales</a></em><a href="https://www.newyorker.com/news/dispatch/the-strange-story-of-dagobert-the-ducktales-bandit">  Bandit: In the &#8217;90s, a frustrated artist in Berlin went on a crime  spree&#8212;building bombs, extorting high-end stores, and styling his persona  after Scrooge McDuck. He soon became a German folk hero.&#8221;</a> (<a href="https://en.wikipedia.org/wiki/Arno_Funke">WP</a>; another reminder for Americans&#8212;odd as it may seem, Donald Duck is <em>extremely</em> popular overseas; see also the unknown-in-the-USA character <a href="https://en.wikipedia.org/wiki/John_D._Rockerduck">John D. Rockerduck</a> or <a href="https://slate.com/culture/2009/12/sweden-s-bizarre-tradition-of-watching-donald-duck-kalle-anka-cartoons-on-christmas-eve.html">beloved Scandinavian tradition</a><em><a href="https://en.wikipedia.org/wiki/From_All_of_Us_to_All_of_You">From All of Us to All of You</a></em> who 2020 airing set an all-time record of &gt;4.5m viewers)</p></li><li><p><a href="https://en.wikipedia.org/wiki/Atmospheric_optics#List">List of atmospheric optical phenomena</a> (How many would you recognize from a distance or plane? How many have you even heard of?)</p></li><li><p><a href="https://en.wikipedia.org/wiki/Franz_Nopcsa_von_Fels%C5%91-Szilv%C3%A1s">Baron Franz Nopcsa von Fels&#337;-Szilv&#225;s</a> (noted geologist, paleontologist, anthropologist, homosexual, &amp; skyjacker)</p></li><li><p><a href="https://en.wikipedia.org/wiki/Krishnacore">Krishnacore</a></p></li></ul><div><hr></div><ol><li><p>What is a diffusion model like DDPM? To try to explain it as simply as possible <a href="https://yang-song.github.io/blog/2021/score/" title="Generative Modeling by Estimating Gradients of the Data Distribution">without the math</a>:</p><p>DDPM is a neural net which is trained to fix noise in an image: it  takes a noisy image and &#8216;sharpens&#8217; it to produce a new image. You train  it by adding dirt to a normal image, and teaching it to turn the dirty  version into the original. As it gets better, it learns what the images  all tend to look like so it can &#8216;see through&#8217; ever more noise, to turn  smudged hints of the original image into its best guess. Once it&#8217;s done  training, what happens if you give it a completely dirty photo, which is  pure static noise? Well, it produces a slightly less dirty &#8216;photo&#8217;. And  if you do it again? it&#8217;s a little cleaner still. Now, what if you do  this many times? It has to get cleaner each time. The end result: the  static noise goes in, and a face pops out! The DDPM has hallucinated a  face out of the noise. One little blob of static here turned into a  nose, and another blob turned into an ear, and it went from there.</p></li></ol></div> <footer class="article-footer" data-astro-cid-wrgicudb> <div class="action-row" data-astro-cid-wrgicudb> <a href="https://gwern.substack.com/p/may-2021-gwernnet-newsletter" target="_blank" rel="noopener noreferrer" class="read-original-btn" data-astro-cid-wrgicudb>
阅读原文 ↗
</a> </div> <div class="back-to-list" data-astro-cid-wrgicudb> <a href="/reading-list" class="back-link" data-astro-cid-wrgicudb>← 返回订阅列表</a> </div> </footer> </article> </div>  </main> <footer class="site-footer" aria-label="Site footer" data-astro-cid-sz7xmlte> <div class="footer-content" data-astro-cid-sz7xmlte> <p class="footer-text" data-astro-cid-sz7xmlte>
&copy; 2026 AstroBlog
</p> <p class="footer-text" data-astro-cid-sz7xmlte>
Built with  <a href="https://astro.build/" target="_blank" rel="noopener noreferrer" class="footer-link" data-astro-cid-sz7xmlte>
Astro
</a> </p> </div> </footer>  </body></html> 